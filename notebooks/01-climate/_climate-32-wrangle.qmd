# STEP 2: Wrangle your data

## Python **packages** let you use code written by experts around the world

Because Python is open source, lots of different people and organizations can contribute (including you!). Many contributions are in the form of **packages** which do not come with a standard Python download.

::: {.callout-read title="Packages need to be installed and imported."}
Learn more about using Python packages. How do you find and use packages? What is the difference between installing and importing packages? When do you need to do each one? [This article on Python packages](https://www.earthdatascience.org/courses/intro-to-earth-data-science/python-code-fundamentals/use-python-packages/) will walk you through the basics.
:::

In the cell below, someone was trying to import the **pandas package**, which helps us to work with [**tabular data** such as comma-separated value or csv files](https://www.earthdatascience.org/courses/intro-to-earth-data-science/file-formats/use-text-files/).

::: {.callout-task title="Import packages"}

  1. Correct the typo below to properly import the pandas package under its **alias** pd.
  2. Run the cell to import the libraries you'll need for this workflow.

:::

::: {.content-visible when-format="ipynb"}
:::: {.callout-warning}
Make sure to run your code in the right **environment** to avoid import errors!

We've created a coding **environment** for you to use that already has all the software and packages you will need! When you try to run some code, you may be prompted to select a **kernel**. The **kernel** refers to the version of Python you are using. You should use the **base** kernel, which should be the default option for you.
::::
:::

```{python}
#| template: student
# Import libraries
import holoviews as hv
import hvplot.pandas
import pandsa as pd
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Import pandas
import holoviews as hv
import hvplot.pandas
import pandas as pd
```
:::

## Download the practice data

Next, lets download some climate data from {{< meta params.location >}} to practice with. We keep our practice data on a website called [figshare](https://figshare.com), so that we can check that it still works and make sure it looks just like the data you would download from the original source. Later, you'll learn how to use our `earthpy` package to download and manage data, and also how to download raw data using **APIs**...but for now we'll keep things simple and use a URL.

The cell below contains the starting point for URL for the data you will use in this part of the notebook. There are three things to notice about the URL code:

  1. It is surrounded by quotes -- that means Python will interpret it as a `string`, or text, type, which makes sense for a URL.
  2. The URL is too long to display as one line on most screens. We've put parentheses around it so that we can easily split it into multiple lines by writing two strings -- one on each line.
  3. We replaced the figshare identifier for this dataset with `'FIGSHARE_ID_HERE'`. You'll have to replace that with the real identifier, {{< meta params.figshare_id>}}

However, we still have a problem - we can't get the URL back later on because it isn't saved in a **variable**. In other words, we need to give the url a **name** so that we can request in from Python later (sadly, Python has no 'hey what was that thingy I typed yesterday?' function).

::: {.callout-read title="Names/variables in Python"}
One of the most common challenges for new programmers is making sure that your results are stored so you can use them again. In Python, this is called **naming**, or saving a **variable**.  Learn more in this [hands-on activity on using variables](https://www.earthdatascience.org/courses/intro-to-earth-data-science/python-code-fundamentals/get-started-using-python/variables/) from our learning portal.
:::

::: {.callout-task title="Save the URL for later"}

  1. Replace `FIGSHARE_ID_HERE` with the figshare id, {{< meta params.figshare_id >}}
  2. Pick an expressive variable name for the URL, and then save the URL using the equals sign `=`. For example, you could save the value `1` to the name `a_number` using the code `a_number = 1`.
  3. At the end of the cell where you define your url variable, **call your variable (type out its name)** so you can see what it is.

:::

```{python}
#| template: student
'https://figshare.com/ndownloader/files/FIGSHARE_ID_HERE'
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
ncei_url = f'https://figshare.com/ndownloader/files/{figshare_id}'
ncei_url
```
:::

The `pandas` library you imported can download data from the internet directly into a type of Python **object** called a `DataFrame`. In the code cell below, you can see an attempt to do just this. But there are some problems...

::: {.callout-task title="Fix some code!"}

  1. Leave a space between the `#` and text in the comment, capitalize it, and try to make it more informative
  2. Make any changes needed to get this code to run. HINT: The `my_url` variable doesn't exist - you need to replace it with the variable name **you** chose.
  3. Modify the `.read_csv()` function call to include the following parameters:

      + `index_col='DATE'` -- this sets the `DATE` column as the index. Needed for subsetting and resampling later on
      + `parse_dates=True` -- this lets `python` know that you are working with time-series data, and values in the indexed column are **date time objects**
      + `na_values=['NaN']` -- this lets `python` know how to handle missing values

  4. Clean up the code by using **expressive variable names**, **expressive column names**, **PEP-8 compliant code**, and **descriptive comments**

:::

```{python}
#| template: student
#download
climate_df = pd.read_csv(
    my_url,
    index_col='something')
climate_df
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Download the climate data
climate_df = pd.read_csv(
    ncei_url,
    index_col='DATE',
    parse_dates=True,
    na_values=['NaN'])
climate_df
```
:::

:::{.callout-tip}
Check out the `type()` function below - you can use it to check that your data is now in `DataFrame` type object.
:::

```{python}
#| template: student
# Check that the data was imported into a pandas DataFrame
type(climate_df)
```

## Clean up your `DataFrame`

::: {.callout-task title="Get rid of unwanted columns"}
You can use **double brackets** (`[[` and `]]`) to select only the columns that you want from your `DataFrame`:

  1. Change `some_column_name` to the Precipitation column name and `another_column_name` to the Observed Temperature column name.
  2. Give the `DataFrame` a more descriptive name.
  3. Add a properly formatted comment to describe what this code is doing.

:::

::: {.callout-warning}
Column names are text values, not variable names, so you need to put them in quotes!
:::

```{python}
#| template: student
climate_df = climate_df[['some_column_name', 'another_column_name']]
climate_df
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Clean up the DataFrame
climate_df = climate_df[['PRCP', 'TOBS']]
climate_df
```
:::

::: {.content-visible when-format="ipynb"}
Great work! You finished the data cleaning section of this coding challenge. You can go on to the next notebook -- but first, make sure to store the climate `DataFrame` you made so that you can use it in the next notebooks. We'll do this using the [ipython `store` **cell magic**](https://ipython.readthedocs.io/en/stable/config/extensions/storemagic.html). [Cell magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html) aren't part of your regular code; they're there to help you with coding in Jupyter Notebooks. You can tell it's a magic command because it starts with `%`:

```{python}
%store climate_df
```
:::
