---
title: The Midwest underwater
subtitle: A look at 2019 floods in South Dakota, USA
image: /img/earth-analytics/flood-frequency/flood.png
image-alt: "A house partially under water, with ruler lines measuring the height"
author: 
  - "Elsa Culler"
  - "Nate Quarderer"
date: last-modified
description: |
  In March 2019, large parts of South Dakota were flooded for weeks. What happened to cause this flooding? What were the impacts on local communities? We will use environmental data to determine where and when flooding happened and how long it lasted. Then, we'll use that same data to put the floods in context historically and discuss how to plan for future disasters.
goals:
  - Use time-series streamflow data from the USGS to identify when flooding occurred
  - Examine potential causes for flooding
  - Describe the impacts of flooding on infrastructure, people, and communities
params:
  id: stars
  site_name: "Cheyenne River near Wasta"
  year: 2019
  project_title: "Cheyenne River Flood Frequency"
  project_dirname: flood-cheyenne
jupyter: python3
---



## Set up

To get started on this notebook, you'll need to restore any variables from previous notebooks to your workspace.

```{python}
%store -r

# Import libraries
```

## STEP 4: Analyse the flood

As scientists and engineers, we are interested in not just describing a flood, but in understanding how often we would expect an event that severe or extreme to happen. Some applications we need this information for include:

  * Designing and developing engineering standards for bridges and roads to withstand flooding
  * Choosing the capacity of water treatment plants to accommodate flood waters
  * Computing flood risk maps and choosing where to build
  * Determining flood insurance rates
  
The exceedance probability is a simple, data-driven way to quantify how unusual a flood is and how often we can expect similar events to happen. We calculate exceedance probability by counting how many years with floods the same size or larger have been recorded, or ranking the and dividing by the number of years we have records for:

 $$P_e = \frac{\text{Annual peak flow rank}}{\text{Years of record}}$$

This value tells us historically what the likelihood was of a flood of a certain size or larger each year, or the **exceedance probability**. We can also express how unusual a flood is with the **return period**, or an amount of time during which we'd expect there to be about one flood the same size or larger. The return period is the reciprocal of the exceedance probability:

  $$R = \frac{\text{Years of record}}{\text{Annual peak flow rank}}$$

As an example -- suppose a streamflow of $10000$ cfs occurs $4$ times over a 100-year record. The exceedance probability would be $\frac{4}{100} = .25$ and the return period would be 25 years.

There are advantages and disadvantages to this method of calculating the **exceedance probability**. On one hand, we are not making any assumptions about how often floods occur, and there is no way to extrapolate to a size of flood that has never been observed. On the other hand, we can't incorporate any information about how often floods occur nearby or in other locations, and the data record for streamflow is often less than the desired lifetime of the built environment.

::: {.callout-read}
You can learn more about exceedance probabilities and return periods in [this textbook page on the subject](https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/floods-return-period-and-probability/)
:::

Let's start by accessing and plotting ALL the data available for this site. Then we'll use a return period **statistic** to quantify how unusual it was.

### Visualize all the streamflow data

::: {.callout-task}
In the cell below, plot the entire time series of streamflow data, without any parameters.
:::

```{python}
#| template: student
# Plot the entire streamflow time series
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Plot the entire streamflow time series
(
    discharge_df
    .plot(
        xlabel='Date', 
        ylabel='Streamflow (cfs)',
        title='90 Years of Streamflow on the Cheyenne River',
        legend=False)
)
```
:::

::: {.callout-respond}
Do you notice anything about this plot?
:::

First things first -- this plot looks a little fuzzy because it is trying to fit too many data points in a small area. There aren't enough pixels in this plot to represent all the data points! One way to improve this is by **resampling** the data to **annual maxima**. That way we still get the same peak streamflows, but the computer will be able to plot all the values without overlapping.

::: {.callout-tip .column-margin}
**Resampling** means changing the time interval between time series observations - in this case from daily to annual.
:::

::: {.callout-read}
Read about [different ways to resample time series data in your textbook](https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/date-time-types-in-pandas-python/resample-time-series-data-pandas-python/)

You can use a [list of **offset aliases**](https://pandas.pydata.org/docs/dev/user_guide/timeseries.html#timeseries-offset-aliases) to look up how to specify the final dates. This list is pretty hard to find - you might want to bookmark it or check back with this page if you need it again.
:::

::: {.callout-task}
Resample your `DataFrame` to get an annual maximum:

  1. Replace `dataframe_name` with the name of your `DataFrame`.
  2. Replace `offset_alias` with the correct offset alias from the [pandas documentation](https://pandas.pydata.org/docs/dev/user_guide/timeseries.html#timeseries-offset-aliases)
  3. Save the results to a new, descriptive variable name, and display the results of the resampling.

:::

```{python}
#| template: student
# Resample to annual maxima
dataframe_name.resample(offset_alias).max()
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Resample to annual maxima
peaks_df = discharge_df.resample('YS').max()
peaks_df
```
:::

::: {.callout-task}
Plot your resampled data.
:::

```{python}
#| template: student
# Plot annual maximum streamflow values
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Plot annual maximum streamflow values
peaks_df.plot(
    figsize=(8, 4),
    xlabel='Year',
    ylabel='Daily Streamflow (cfs)',
    title='Annual Maximum Daily Streamflow Values on the Cheyenne River',
    legend=False)
```
:::

::: {.callout-respond}
Write a headline and 2-3 sentence description of your plot. What is your visual estimate of the return period was for the flood in 2019?
:::

::: {.content-visible when-format="ipynb"}
:::: {.cell .markdown}
YOUR HEADLINE AND PLOT DESCRIPTION HERE
::::
:::

### Select relevant data

When calculating exceedance probabilities, we are making an assumption of **stationarity**, meaning that all the peak streamflows are drawn from the same **probability distribution**. Put another way, we only want to include data from years where the conditions on the river are similar to what they are now. 

Did you notice that the streamflow values from before 1950 or so? You should investigate any obvious causes of that discrepancy so we know if the pre-1950 data is relevant to current conditions.

::: {.callout-respond}
What are some possible causes for peak streamflows to decrease systematically?
:::

::: {.callout-info .column-margin title='Climate Change and Stationarity'}
One of the problems with adapting to climate change is that we can no longer assume stationarity in a lot of contexts. As scientists, we don't yet have standard methods for incorporating climate change into flood return period calculations. You can read more about the debate of stationarity, climate change, and return periods in [a paper called 'Stationarity is Dead'](https://www.science.org/doi/10.1126/science.1151915) and the many related response papers.
:::

It turns out that construction on the Oahe dam on the Cheyenne River was started in 1948. We therefor don't want to include any streamflow measurements before that date, because the Cheyenne River now as a much different flood response due to the dam. Dams tend to reduce peak streamflow, depending on how they are managed, but can cause other problems in the process.

::: {.callout-read}
Learn more about the Oahe Dam on [its Wikipedia page](https://en.wikipedia.org/wiki/Oahe_Dam). You can also find some local perspectives on the dam in some of the articles about the 2019 flood at the beginning of this coding challenge.
:::

::: {.callout-task}
Remove years of data before the construction of the Oahe Dam. You can use a colon inside the square brackets of the `.loc` attribute to show that you would like all dates after a certain value, e.g. `'1950':`
:::

```{python}
#| template: student
# Select data from after dam construction
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
peaks_df = peaks_df.loc['1948':]
peaks_df
```
:::

### Calculate the exceedance probability and return period for 2019

::: {.callout-extra}
Calculate the **exceedance probability** and **return period** for each year of the **annual** data, and add them as columns to your DataFrame.

  1. Replace `df` with the name of your **annual maximum** `DataFrame`.
  2. Replace `col` with the name of your streamflow column
  3. Calculate the return period using Python mathematical operators
  
:::

::: {.callout-tip}
When you use a Python mathematical operator on a `pandas.DataFrame` column, Python will do the calculation for every row in the `DataFrame` automatically!
:::

::: {.callout-tip .column-margin}
When you rank the floods in your `DataFrame` with the `.rank()` method, you will need the ascending=False` parameter, by default the largest floods will have the higher number. We use `ascending=Falsa` to reverse the rankings, since higher rank should be lower exceedence probability.
:::

```{python}
#| template: student
df['exceed_prob'] = (df.rank(ascending=False).col / len(df))
df['return_period'] = 

peaks_df
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Make a copy so this is a dataframe and not a view
peaks_df = peaks_df.copy()

# Calculate exceedance probability
peaks_df['exceed_prob'] = (
    peaks_df.rank(ascending=False).streamflow_cfs 
    / len(peaks_df)
)
# Calculate return period
peaks_df['return_period'] = 1 / peaks_df.exceed_prob

peaks_df
```
:::

::: {.callout-task}
Select only the value for 2019.

  1. Replace `dataframe_name` with the name of your `DataFrame`
  2. Inside the square brackets, type the year you want to select (2019). Make sure to surround the year with quotes, or Python will interpret this as a **row number**.
  
:::

```{python}
#| template: student
dataframe_name.loc[]
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
peaks_df.loc['2019']
```
:::

::: {.callout-respond}
What is the exceedance probability and return period for the 2019 floods on the Cheyenne River?
:::

::: {.content-visible when-format="ipynb"}
:::: {.cell .markdown}
PROBABILITY AND RETURN PERIOD HERE
::::
:::

## Wrap up

Don't forget to store your variables so you can use them in other notebooks! This code will store all your variables. You might want to specify specific variables, especially if you have large objects in memory that you won't need in the future.

```{python}
%store
```

Finally, be sure to `Restart` and `Run all` to make sure your notebook works all the way through!
