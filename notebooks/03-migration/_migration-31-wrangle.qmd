## STEP 1: Set up your reproducible workflow

### Import Python libraries

::: {.callout-task title="Import packages"}

In the imports cell, we've included some packages that you will need. Add imports for packages that will help you:

1.  Work with tabular data
2.  Work with geospatial vector data

:::

```{python}
#| template: student
import os
import pathlib

import earthpy
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
import os
import pathlib

import earthpy
import geopandas as gpd
import pandas as pd
```
:::

### Create a directory for your data

For this challenge, you will need to download some data to the computer you're working on. We suggest using the `earthpy` library we develop to manage your downloads, since it encapsulates many best practices as far as:

  1. Where to store your data
  2. Dealing with archived data like .zip files
  3. Avoiding version control problems
  4. Making sure your code works cross-platform
  5. Avoiding duplicate downloads 
  
If you're working on one of our assignments through GitHub Classroom, it also lets us build in some handy defaults so that you can see your data files while you work.

::: {.callout-task title="Create a project folder"}
The code below will help you get started with making a project directory

1.  Replace `'your-project-directory-name-here'` with a **descriptive** name
2.  Run the cell
3.  The code should have printed out the path to your data files. Check that your data directory exists and has data in it using the terminal or your Finder/File Explorer.
:::

::: {.callout-tip .column-margin title="File structure"}
These days, a lot of people find your file by searching for them or selecting from a `Bookmarks` or `Recents` list. Even if you don't use it, your computer also keeps files in a **tree** structure of folders. Put another way, you can organize and find files by travelling along a unique **path**, e.g. `My Drive` > `Documents` > `My awesome project` > `A project file` where each subsequent folder is **inside** the previous one. This is convenient because all the files for a project can be in the same place, and both people and computers can rapidly locate files they want, provided they remember the path.

You may notice that when Python prints out a file path like this, the folder names are **separated** by a `/` or `\` (depending on your operating system). This character is called the **file separator**, and it tells you that the next piece of the path is **inside** the previous one.
:::

```{python}
#| template: student
# Create data directory
project = earthpy.Project(
    title=project_title,
    dirname='your-project-directory-name-here')
# Download sample data
project.get_data()

# Display the project directory
project.project_dir
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Create data directory
project = earthpy.Project(title=project_title)
# Download sample data
project.get_data()

# Display the project directory
project.project_dir
```
:::

## STEP 2: Define your study area -- the ecoregions of North America

Your sample data package included a Shapefile of global **ecoregions**. You should be able to see changes in the number of observations of {{< meta params.species_name>}} in each ecoregion throughout the year.

::: {.callout-info .column-margin}
You don't have to use ecoregions to group species observations -- you could choose to use political boundaries like countries or states, other natural boundaries like watersheds, or even uniform hexagonal areas as is common in conservation work. We chose ecoregions because we expect the suitability for a species at a particular time of year to be relatively consistent across the region.
:::

::: {.callout-read}
The ecoregion data will be available as a **shapefile**. Learn more about shapefiles and vector data in this [Introduction to Spatial Vector Data File Formats in Open Source Python](https://www.earthdatascience.org/courses/intro-to-earth-data-science/file-formats/use-spatial-data/use-vector-data/)
:::

### Load the ecoregions into Python

::: {.callout-task title="Load ecoregions into Python"}

Download and save ecoregion boundaries from the EPA:

1.  Replace `a_path` with the path your created for your ecoregions file.
2.  (optional) Consider renaming and selecting columns to make your `GeoDataFrame` easier to work with. Many of the same methods you learned for `pandas` `DataFrame`s are the same for `GeoDataFrame`s! NOTE: Make sure to keep the `'SHAPE_AREA'` column around -- we will need that later!
3.  Make a quick plot with `.plot()` to make sure the download worked.
4.  Run the cell to load the data into Python
:::

```{python}
#| template: student
# Open up the ecoregions boundaries
gdf = gpd.read_file(a_path)

# Name the index so it will match the other data later on
gdf.index.name = 'ecoregion'

# Plot the ecoregions quickly to check download
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Open up the ecoregions boundaries
ecoregions_gdf = (
    gpd.read_file(project.project_dir / ecoregions_dir)
    .rename(columns={
        'ECO_NAME': 'name',
        'SHAPE_AREA': 'area'})
    [['name', 'area', 'geometry']]
)

# We'll name the index so it will match the other data
ecoregions_gdf.index.name = 'ecoregion'

# Plot the ecoregions quickly to check download
ecoregions_gdf.plot(edgecolor='black', color='skyblue')
```
:::

## STEP 3: Load species observation data

For this challenge, you will use a database called the [Global Biodiversity Information Facility (GBIF)](https://www.gbif.org/). GBIF is compiled from species observation data all over the world, and includes everything from museum specimens to photos taken by citizen scientists in their backyards. We've compiled some sample data in the same format that you will get from GBIF.

Let's start by looking at a little of the raw data.

```{python}
gbif_path = project.project_dir / gbif_filename
```

::: {.callout-task title="Load GBIF data"}

1.  Look at the beginning of the file you downloaded using the code below. What do you think the **delimiter** is?
2.  Run the following code cell. What happens?
3.  Uncomment and modify the parameters of `pd.read_csv()` below until your data loads successfully and you have only the columns you want.
:::

You can use the following code to look at the beginning of your file:

```{python}
!head -n 2 $gbif_path 
```

```{python}
#| template: student
# Load the GBIF data
gbif_df = pd.read_csv(
    gbif_path, 
    delimiter='',
    index_col='',
    usecols=[]
)
gbif_df.head()
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Load the GBIF data
gbif_df = pd.read_csv(
    gbif_path, 
    delimiter='\t',
    index_col='gbifID',
    usecols=['gbifID', 'decimalLatitude', 'decimalLongitude', 'month'])
gbif_df.head()
```
:::

### Convert the GBIF data to a GeoDataFrame

To plot the GBIF data, we need to convert it to a `GeoDataFrame` first. This will make some special geospatial operations from `geopandas` available, such as spatial joins and plotting.

::: {.callout-task title="Convert `DataFrame` to `GeoDataFrame`"}

1.  Replace `your_dataframe` with the name of the `DataFrame` you just got from GBIF
2.  Replace `longitude_column_name` and `latitude_column_name` with column names from your \`DataFrame
3.  Run the code to get a `GeoDataFrame` of the GBIF data.
:::

```{python}
#| template: student
gbif_gdf = (
    gpd.GeoDataFrame(
        your_dataframe, 
        geometry=gpd.points_from_xy(
            your_dataframe.longitude_column_name, 
            your_dataframe.latitude_column_name), 
        crs="EPSG:4326")
    # Select the desired columns
    [[]]
)
gbif_gdf
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
gbif_gdf = (
    gpd.GeoDataFrame(
        gbif_df, 
        geometry=gpd.points_from_xy(
            gbif_df.decimalLongitude, 
            gbif_df.decimalLatitude), 
        crs="EPSG:4326")
    # Select the desired columns
    [['month', 'geometry']]
)
gbif_gdf
```
:::

::: {.content-visible when-format="ipynb"}
::: {.callout-task}
Make sure to store the new version of your `DataFrame` for other notebooks!
```{python}
%store ecoregions_gdf gbif_gdf
```
:::
:::
