[
  {
    "objectID": "notebooks/03-species-distribution/species-distribution.html",
    "href": "notebooks/03-species-distribution/species-distribution.html",
    "title": "Mapping Tasiyagnunpa (Western Meadowlark) migration",
    "section": "",
    "text": "Tasiyagnunpa (or Western Meadowlark, or sturnella neglecta) migrates each year to nest on the Great Plains in the United States. Using crowd-sourced observations of these birds, we can see that migration happening throughout the year.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 3: Species Distribution",
      "Mapping Tasiyagnunpa (Western Meadowlark) migration"
    ]
  },
  {
    "objectID": "notebooks/03-species-distribution/species-distribution.html#set-up-your-reproducible-workflow",
    "href": "notebooks/03-species-distribution/species-distribution.html#set-up-your-reproducible-workflow",
    "title": "Mapping Tasiyagnunpa (Western Meadowlark) migration",
    "section": "Set up your reproducible workflow",
    "text": "Set up your reproducible workflow\n\nImport Python libraries\nWe will be getting data from a source called GBIF (Global Biodiversity Information Facility). We need a package called pygbif to access the data, which is not included in your environment. Install it by running the cell below:\n\n%%bash\npip install pygbif\n\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your Task: Import packages\n\n\n\nAdd imports for packages that will help you:\n\nWork with tabular data\nWork with geospatial vector data\nMake an interactive plot of tabular and/or vector data\n\n\n\n\nimport calendar\nimport os\nimport pathlib\nimport requests\nimport time\nimport zipfile\nfrom getpass import getpass\nfrom glob import glob\n\nimport cartopy.crs as ccrs\nimport panel as pn\nimport pygbif.occurrences as occ\nimport pygbif.species as species\n\nERROR 1: PROJ: proj_create_from_database: Open of /usr/share/miniconda/envs/learning-portal/share/proj failed\n\n\n\n\nSee our solution!\nimport calendar\nimport os\nimport pathlib\nimport requests\nimport time\nimport zipfile\nfrom getpass import getpass\nfrom glob import glob\n\nimport cartopy.crs as ccrs\nimport geopandas as gpd\nimport hvplot.pandas\nimport pandas as pd\nimport panel as pn\nimport pygbif.occurrences as occ\nimport pygbif.species as species\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nCreate a folder for your data\nFor this challenge, you will need to save some data to your computer. We suggest saving to somewhere in your home folder (e.g. /home/username), rather than to your GitHub repository, since data files can easily become too large for GitHub.\n\n\n\n\n\n\nWarning\n\n\n\nThe home directory is different for every user! Your home directory probably won’t exist on someone else’s computer. Make sure to use code like pathlib.Path.home() to compute the home directory on the computer the code is running on. This is key to writing reproducible and interoperable code.\n\n\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your Task: Create a project folder\n\n\n\nThe code below will help you get started with making a project directory\n\nReplace 'your-project-directory-name-here' and 'your-gbif-data-directory-name-here' with descriptive names\nRun the cell\n(OPTIONAL) Check in the terminal that you created the directory using the command ls ~/earth-analytics/data\n\n\n\n\n# Create data directory in the home folder\ndata_dir = os.path.join(\n    # Home directory\n    pathlib.Path.home(),\n    # Earth analytics data directory\n    'earth-analytics',\n    'data',\n    # Project directory\n    'your-project-directory-name-here',\n)\nos.makedirs(data_dir, exist_ok=True)\n\n# Define the directory name for GBIF data\ngbif_dir = os.path.join(data_dir, 'your-gbif-data-directory-name-here')\n\n\n\nSee our solution!\n# Create data directory in the home folder\ndata_dir = os.path.join(\n    pathlib.Path.home(),\n    'earth-analytics',\n    'data',\n    'species-distribution',\n)\nos.makedirs(data_dir, exist_ok=True)\n\n# Define the directory name for GBIF data\ngbif_dir = os.path.join(data_dir, 'meadowlark_observations')",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 3: Species Distribution",
      "Mapping Tasiyagnunpa (Western Meadowlark) migration"
    ]
  },
  {
    "objectID": "notebooks/03-species-distribution/species-distribution.html#define-your-study-area-the-ecoregions-of-north-america",
    "href": "notebooks/03-species-distribution/species-distribution.html#define-your-study-area-the-ecoregions-of-north-america",
    "title": "Mapping Tasiyagnunpa (Western Meadowlark) migration",
    "section": "Define your study area – the ecoregions of North America",
    "text": "Define your study area – the ecoregions of North America\nTrack observations of Taciyagnunpa across the different ecoregions of North America! You should be able to see changes in the number of observations in each ecoregion throughout the year.\n\nDownload and save ecoregion boundaries\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your Task\n\n\n\n\nFind the URL for for the level III ecoregion boundaries. You can get ecoregion boundaries from the Environmental Protection Agency (EPA)..\nReplace your/url/here with the URL you found, making sure to format it so it is easily readable.\nChange all the variable names to descriptive variable names\nRun the cell to download and save the data.\n\n\n\n\n# Set up the ecoregions level III boundary URL\na_url = (\"your/url/here\")\n# Set up a path to save the dataon your machine\na_path = os.path.join(data_dir, 'filename.zip')\n\n# Don't download twice\nif not os.path.exists(a_path):\n    # Download, and don't check the certificate for the EPA\n    a_response = requests.get(a_url, verify=False)\n    # Save the binary data to a file\n    with open(a_path, 'wb') as a_file:\n        a_file.write(a_response.content)\n\n\n---------------------------------------------------------------------------\nMissingSchema                             Traceback (most recent call last)\nCell In[6], line 9\n      6 # Don't download twice\n      7 if not os.path.exists(a_path):\n      8     # Download, and don't check the certificate for the EPA\n----&gt; 9     a_response = requests.get(a_url, verify=False)\n     10     # Save the binary data to a file\n     11     with open(a_path, 'wb') as a_file:\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/requests/api.py:73, in get(url, params, **kwargs)\n     62 def get(url, params=None, **kwargs):\n     63     r\"\"\"Sends a GET request.\n     64 \n     65     :param url: URL for the new :class:`Request` object.\n   (...)\n     70     :rtype: requests.Response\n     71     \"\"\"\n---&gt; 73     return request(\"get\", url, params=params, **kwargs)\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/requests/api.py:59, in request(method, url, **kwargs)\n     55 # By using the 'with' statement we are sure the session is closed, thus we\n     56 # avoid leaving sockets open which can trigger a ResourceWarning in some\n     57 # cases, and look like a memory leak in others.\n     58 with sessions.Session() as session:\n---&gt; 59     return session.request(method=method, url=url, **kwargs)\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/requests/sessions.py:575, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\n    562 # Create the Request.\n    563 req = Request(\n    564     method=method.upper(),\n    565     url=url,\n   (...)\n    573     hooks=hooks,\n    574 )\n--&gt; 575 prep = self.prepare_request(req)\n    577 proxies = proxies or {}\n    579 settings = self.merge_environment_settings(\n    580     prep.url, proxies, stream, verify, cert\n    581 )\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/requests/sessions.py:484, in Session.prepare_request(self, request)\n    481     auth = get_netrc_auth(request.url)\n    483 p = PreparedRequest()\n--&gt; 484 p.prepare(\n    485     method=request.method.upper(),\n    486     url=request.url,\n    487     files=request.files,\n    488     data=request.data,\n    489     json=request.json,\n    490     headers=merge_setting(\n    491         request.headers, self.headers, dict_class=CaseInsensitiveDict\n    492     ),\n    493     params=merge_setting(request.params, self.params),\n    494     auth=merge_setting(auth, self.auth),\n    495     cookies=merged_cookies,\n    496     hooks=merge_hooks(request.hooks, self.hooks),\n    497 )\n    498 return p\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/requests/models.py:367, in PreparedRequest.prepare(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\n    364 \"\"\"Prepares the entire request with the given parameters.\"\"\"\n    366 self.prepare_method(method)\n--&gt; 367 self.prepare_url(url, params)\n    368 self.prepare_headers(headers)\n    369 self.prepare_cookies(cookies)\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/requests/models.py:438, in PreparedRequest.prepare_url(self, url, params)\n    435     raise InvalidURL(*e.args)\n    437 if not scheme:\n--&gt; 438     raise MissingSchema(\n    439         f\"Invalid URL {url!r}: No scheme supplied. \"\n    440         f\"Perhaps you meant https://{url}?\"\n    441     )\n    443 if not host:\n    444     raise InvalidURL(f\"Invalid URL {url!r}: No host supplied\")\n\nMissingSchema: Invalid URL 'your/url/here': No scheme supplied. Perhaps you meant https://your/url/here?\n\n\n\n\n\nSee our solution!\n# Set up the ecoregions level III boundary URL\necoregions_url = (\n    \"https://gaftp.epa.gov/EPADataCommons/ORD/Ecoregions/cec_na\"\n    \"/NA_CEC_Eco_Level3.zip\")\n# Set up a path to save the dataon your machine\necoregions_path = os.path.join(data_dir, 'NA_CEC_Eco_Level3.zip')\n\n# Don't download twice\nif not os.path.exists(ecoregions_path):\n    # Download\n    ecoregions_response = requests.get(ecoregions_url, verify=False)\n    # Save the data to your file\n    with open(ecoregions_path, 'wb') as ecoregions_file:\n        ecoregions_file.write(ecoregions_response.content)\n\n\n/usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'gaftp.epa.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n\n\n\n\nLoad the ecoregions into Python\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task\n\n\n\nDownload and save ecoregion boundaries from the EPA:\n\nReplace a_path with the path your created for your ecoregions file.\n(optional) Consider renaming and selecting columns to make your GeoDataFrame easier to work with.\nMake a quick plot with .plot() to make sure the download worked.\nRun the cell to load the data into Python\n\n\n\n\n# Open up the ecoregions boundaries\ngdf = gpd.read_file(a_path)\n\n# Name the index so it will match the other data later on\ngdf.index.name = 'ecoregion'\n\n# Plot the ecoregions to check download\n\nERROR:`/vsizip//home/runner/earth-analytics/data/species-distribution/filename.zip' does not exist in the file system, and is not recognized as a supported dataset name.\n\n\n\n---------------------------------------------------------------------------\nCPLE_OpenFailedError                      Traceback (most recent call last)\nFile fiona/ogrext.pyx:136, in fiona.ogrext.gdal_open_vector()\n\nFile fiona/_err.pyx:291, in fiona._err.exc_wrap_pointer()\n\nCPLE_OpenFailedError: '/vsizip//home/runner/earth-analytics/data/species-distribution/filename.zip' does not exist in the file system, and is not recognized as a supported dataset name.\n\nDuring handling of the above exception, another exception occurred:\n\nDriverError                               Traceback (most recent call last)\nCell In[8], line 2\n      1 # Open up the ecoregions boundaries\n----&gt; 2 gdf = gpd.read_file(a_path)\n      4 # Name the index so it will match the other data later on\n      5 gdf.index.name = 'ecoregion'\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/geopandas/io/file.py:289, in _read_file(filename, bbox, mask, rows, engine, **kwargs)\n    286     else:\n    287         path_or_bytes = filename\n--&gt; 289     return _read_file_fiona(\n    290         path_or_bytes, from_bytes, bbox=bbox, mask=mask, rows=rows, **kwargs\n    291     )\n    293 else:\n    294     raise ValueError(f\"unknown engine '{engine}'\")\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/geopandas/io/file.py:315, in _read_file_fiona(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\n    312     reader = fiona.open\n    314 with fiona_env():\n--&gt; 315     with reader(path_or_bytes, **kwargs) as features:\n    316         crs = features.crs_wkt\n    317         # attempt to get EPSG code\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/fiona/env.py:457, in ensure_env_with_credentials.&lt;locals&gt;.wrapper(*args, **kwds)\n    454     session = DummySession()\n    456 with env_ctor(session=session):\n--&gt; 457     return f(*args, **kwds)\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/fiona/__init__.py:292, in open(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\n    289     path = parse_path(fp)\n    291 if mode in (\"a\", \"r\"):\n--&gt; 292     colxn = Collection(\n    293         path,\n    294         mode,\n    295         driver=driver,\n    296         encoding=encoding,\n    297         layer=layer,\n    298         enabled_drivers=enabled_drivers,\n    299         allow_unsupported_drivers=allow_unsupported_drivers,\n    300         **kwargs\n    301     )\n    302 elif mode == \"w\":\n    303     colxn = Collection(\n    304         path,\n    305         mode,\n   (...)\n    314         **kwargs\n    315     )\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/fiona/collection.py:243, in Collection.__init__(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\n    241 if self.mode == \"r\":\n    242     self.session = Session()\n--&gt; 243     self.session.start(self, **kwargs)\n    244 elif self.mode in (\"a\", \"w\"):\n    245     self.session = WritingSession()\n\nFile fiona/ogrext.pyx:588, in fiona.ogrext.Session.start()\n\nFile fiona/ogrext.pyx:143, in fiona.ogrext.gdal_open_vector()\n\nDriverError: '/vsizip//home/runner/earth-analytics/data/species-distribution/filename.zip' does not exist in the file system, and is not recognized as a supported dataset name.\n\n\n\n\n\nSee our solution!\n# Open up the ecoregions boundaries\necoregions_gdf = (\n    gpd.read_file(ecoregions_path)\n    .rename(columns={\n        'NA_L3NAME': 'name',\n        'Shape_Area': 'area'})\n    [['name', 'area', 'geometry']]\n)\n\n# We'll name the index so it will match the other data\necoregions_gdf.index.name = 'ecoregion'\n\n# Plot the ecoregions to check download\necoregions_gdf.plot(edgecolor='black', color='skyblue')\n\n\n\n\n\n\n\n\n\n\n\nCreate a simplified GeoDataFrame for plotting\nPlotting larger files can be time consuming. The code below will streamline plotting with hvplot by simplifying the geometry, projecting it to a Mercator projection that is compatible with geoviews, and cropping off areas in the Arctic.\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task\n\n\n\nDownload and save ecoregion boundaries from the EPA:\n\nMake a copy of your ecoregions GeoDataFrame with the .copy() method, and save it to another variable name. Make sure to do everything else in this cell with your new copy!\nSimplify the ecoregions with .simplify(1000), and save it back to the geometry column.\nChange the Coordinate Reference System (CRS) to Mercator with .to_crs(ccrs.Mercator())\nUse the plotting code in the cell to check that the plotting runs quickly and looks the way you want, making sure to change gdf to YOUR GeoDataFrame name.\n\n\n\n\n# Make a copy of the ecoregions\n\n# Simplify the geometry to speed up processing\n\n# Change the CRS to Mercator for mapping\n\n# Check that the plot runs\ngdf.hvplot(geo=True, crs=ccrs.Mercator())\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[10], line 8\n      1 # Make a copy of the ecoregions\n      2 \n      3 # Simplify the geometry to speed up processing\n   (...)\n      6 \n      7 # Check that the plot runs\n----&gt; 8 gdf.hvplot(geo=True, crs=ccrs.Mercator())\n\nNameError: name 'gdf' is not defined\n\n\n\n\n\nSee our solution!\n# Make a copy of the ecoregions\necoregions_plot_gdf = ecoregions_gdf.copy()\n\n# Simplify the geometry to speed up processing\necoregions_plot_gdf.geometry = ecoregions_plot_gdf.simplify(1000)\n\n# Change the CRS to Mercator for mapping\necoregions_plot_gdf = ecoregions_plot_gdf.to_crs(ccrs.Mercator())\n\n# Check that the plot runs\necoregions_plot_gdf.hvplot(geo=True, crs=ccrs.Mercator())",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 3: Species Distribution",
      "Mapping Tasiyagnunpa (Western Meadowlark) migration"
    ]
  },
  {
    "objectID": "notebooks/03-species-distribution/species-distribution.html#access-locations-and-times-of-tasiyagnunpa-encounters",
    "href": "notebooks/03-species-distribution/species-distribution.html#access-locations-and-times-of-tasiyagnunpa-encounters",
    "title": "Mapping Tasiyagnunpa (Western Meadowlark) migration",
    "section": "Access locations and times of Tasiyagnunpa encounters",
    "text": "Access locations and times of Tasiyagnunpa encounters\nFor this challenge, you will use a database called the Global Biodiversity Information Facility (GBIF). GBIF is compiled from species observation data all over the world, and includes everything from museum specimens to photos taken by citizen scientists in their backyards.\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task: Explore GBIF\n\n\n\nBefore your get started, go to the GBIF occurrences search page and explore the data.\n\n\n\n\n\n\n\n\nContribute to open data\n\n\n\nYou can get your own observations added to GBIF using iNaturalist!\n\n\n\nRegister and log in to GBIF\nYou will need a GBIF account to complete this challenge. You can use your GitHub account to authenticate with GBIF. Then, run the following code to save your credentials on your computer.\n\n\n\n\n\n\nTip\n\n\n\nIf you accidentally enter your credentials wrong, you can set reset_credentials=True instead of reset_credentials=False\n\n\n\nreset_credentials = False\n# GBIF needs a username, password, and email\ncredentials = dict(\n    GBIF_USER=(input, 'GBIF username:'),\n    GBIF_PWD=(getpass, 'GBIF password'),\n    GBIF_EMAIL=(input, 'GBIF email'),\n)\nfor env_variable, (prompt_func, prompt_text) in credentials.items():\n    # Delete credential from environment if requested\n    if reset_credentials and (env_variable in os.environ):\n        os.environ.pop(env_variable)\n    # Ask for credential and save to environment\n    if not env_variable in os.environ:\n        os.environ[env_variable] = prompt_func(prompt_text)\n\n\n\nGet the species key\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task\n\n\n\n\nReplace the species_name with the name of the species you want to look up\nRun the code to get the species key\n\n\n\n\n# Query species\nspecies_info = species.name_lookup(species_name, rank='SPECIES')\n\n# Get the first result\nfirst_result = species_info['results'][0]\n\n# Get the species key (nubKey)\nspecies_key = first_result['nubKey']\n\n# Check the result\nfirst_result['species'], species_key\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[13], line 2\n      1 # Query species\n----&gt; 2 species_info = species.name_lookup(species_name, rank='SPECIES')\n      4 # Get the first result\n      5 first_result = species_info['results'][0]\n\nNameError: name 'species_name' is not defined\n\n\n\n\n\nSee our solution!\n# Query species\nspecies_info = species.name_lookup('sturnella neglecta', rank='SPECIES')\n\n# Get the first result\nfirst_result = species_info['results'][0]\n\n# Get the species key (nubKey)\nspecies_key = first_result['nubKey']\n\n# Check the result\nfirst_result['species'], species_key\n\n\n('Sturnella neglecta', 9596413)\n\n\n\n\nDownload data from GBIF\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task\n\n\n\n\nReplace csv_file_pattern with a string that will match any .csv file when used in the glob function. HINT: the character * represents any number of any values except the file separator (e.g. /)\nAdd parameters to the GBIF download function, occ.download() to limit your query to:\n\nSturnella Neglecta observations\nin north america (NORTH_AMERICA)\nfrom 2023\nwith spatial coordinates.\n\nThen, run the download. This can take a few minutes.\n\n\n\n\n# Only download once\ngbif_pattern = os.path.join(gbif_dir, csv_file_pattern)\nif not glob(gbif_pattern):\n    # Submit query to GBIF\n    gbif_query = occ.download([\n        \"continent = \",\n        \"speciesKey = \",\n        \"year = \",\n        \"hasCoordinate = \",\n    ])\n    if not 'GBIF_DOWNLOAD_KEY' in os.environ:\n        os.environ['GBIF_DOWNLOAD_KEY'] = gbif_query[0]\n\n        # Wait for the download to build\n        wait = occ.download_meta(download_key)['status']\n        while not wait=='SUCCEEDED':\n            wait = occ.download_meta(download_key)['status']\n            time.sleep(5)\n\n    # Download GBIF data\n    download_info = occ.download_get(\n        os.environ['GBIF_DOWNLOAD_KEY'], \n        path=data_dir)\n\n    # Unzip GBIF data\n    with zipfile.ZipFile(download_info['path']) as download_zip:\n        download_zip.extractall(path=gbif_dir)\n\n# Find the extracted .csv file path\ngbif_path = glob(gbif_pattern)[0]\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[15], line 2\n      1 # Only download once\n----&gt; 2 gbif_pattern = os.path.join(gbif_dir, csv_file_pattern)\n      3 if not glob(gbif_pattern):\n      4     # Submit query to GBIF\n      5     gbif_query = occ.download([\n      6         \"continent = \",\n      7         \"speciesKey = \",\n      8         \"year = \",\n      9         \"hasCoordinate = \",\n     10     ])\n\nNameError: name 'csv_file_pattern' is not defined\n\n\n\n\n\nSee our solution!\n# Only download once\ngbif_pattern = os.path.join(gbif_dir, '*.csv')\nif not glob(gbif_pattern):\n    # Submit query to GBIF\n    gbif_query = occ.download([\n        \"continent = NORTH_AMERICA\",\n        \"speciesKey = 9596413\",\n        \"hasCoordinate = TRUE\",\n        \"year = 2023\",\n    ])\n    download_key = gbif_query[0]\n\n    # Wait for the download to build\n    if not 'GBIF_DOWNLOAD_KEY' in os.environ:\n        os.environ['GBIF_DOWNLOAD_KEY'] = gbif_query[0]\n\n        # Wait for the download to build\n        wait = occ.download_meta(download_key)['status']\n        while not wait=='SUCCEEDED':\n            wait = occ.download_meta(download_key)['status']\n            time.sleep(5)\n\n    # Download GBIF data\n    download_info = occ.download_get(\n        os.environ['GBIF_DOWNLOAD_KEY'], \n        path=data_dir)\n\n    # Unzip GBIF data\n    with zipfile.ZipFile(download_info['path']) as download_zip:\n        download_zip.extractall(path=gbif_dir)\n\n# Find the extracted .csv file path (take the first result)\ngbif_path = glob(gbif_pattern)[0]\n\n\nINFO:Your download key is 0105454-240626123714530\nINFO:Download file size: 26559580 bytes\nINFO:On disk at /home/runner/earth-analytics/data/species-distribution/0022779-240506114902167.zip\n\n\n\n\nLoad the GBIF data into Python\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task\n\n\n\n\nLook at the beginning of the file you downloaded using the code below. What do you think the delimiter is?\nRun the following code cell. What happens?\nUncomment and modify the parameters of pd.read_csv() below until your data loads successfully and you have only the columns you want.\n\n\n\nYou can use the following code to look at the beginning of your file:\n\n!head -n 2 $gbif_path \n\ngbifID  datasetKey  occurrenceID    kingdom phylum  class   order   family  genus   species infraspecificEpithet    taxonRank   scientificName  verbatimScientificName  verbatimScientificNameAuthorship    countryCode locality    stateProvince   occurrenceStatus    individualCount publishingOrgKey    decimalLatitude decimalLongitude    coordinateUncertaintyInMeters   coordinatePrecision elevation   elevationAccuracy   depth   depthAccuracy   eventDate   day month   year    taxonKey    speciesKey  basisOfRecord   institutionCode collectionCode  catalogNumber   recordNumber    identifiedBy    dateIdentified  license rightsHolder    recordedBy  typeStatus  establishmentMeans  lastInterpreted mediaType   issue\n4617234711  4fa7b334-ce0d-4e88-aaae-2e0c138d049e    URN:catalog:CLO:EBIRD:OBS1665858440 Animalia    Chordata    Aves    Passeriformes   Icteridae   Sturnella   Sturnella neglecta      SPECIES Sturnella neglecta Audubon, 1844    Sturnella neglecta      US  61575–61597 OR-205, Burns US-OR (43.3530,-118.9791) Oregon  PRESENT 1   e2e717bf-551a-4917-bdc9-4fa0f342c530    43.35301    -118.97914                          2023-03-24  24  3   2023    9596413 9596413 HUMAN_OBSERVATION   CLO EBIRD   OBS1665858440               CC_BY_4_0       obsr945588          2024-04-17T09:01:34.460Z        CONTINENT_DERIVED_FROM_COORDINATES;TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED\n\n\n\n# Load the GBIF data\ngbif_df = pd.read_csv(\n    gbif_path, \n    #delimiter='',\n    #index_col='',\n    #usecols=[]\n)\ngbif_df.head()\n\n\n---------------------------------------------------------------------------\nParserError                               Traceback (most recent call last)\nCell In[18], line 2\n      1 # Load the GBIF data\n----&gt; 2 gbif_df = pd.read_csv(\n      3     gbif_path, \n      4     #delimiter='',\n      5     #index_col='',\n      6     #usecols=[]\n      7 )\n      8 gbif_df.head()\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626, in _read(filepath_or_buffer, kwds)\n    623     return parser\n    625 with parser:\n--&gt; 626     return parser.read(nrows)\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923, in TextFileReader.read(self, nrows)\n   1916 nrows = validate_integer(\"nrows\", nrows)\n   1917 try:\n   1918     # error: \"ParserBase\" has no attribute \"read\"\n   1919     (\n   1920         index,\n   1921         columns,\n   1922         col_dict,\n-&gt; 1923     ) = self._engine.read(  # type: ignore[attr-defined]\n   1924         nrows\n   1925     )\n   1926 except Exception:\n   1927     self.close()\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234, in CParserWrapper.read(self, nrows)\n    232 try:\n    233     if self.low_memory:\n--&gt; 234         chunks = self._reader.read_low_memory(nrows)\n    235         # destructive to chunks\n    236         data = _concatenate_chunks(chunks)\n\nFile parsers.pyx:838, in pandas._libs.parsers.TextReader.read_low_memory()\n\nFile parsers.pyx:905, in pandas._libs.parsers.TextReader._read_rows()\n\nFile parsers.pyx:874, in pandas._libs.parsers.TextReader._tokenize_rows()\n\nFile parsers.pyx:891, in pandas._libs.parsers.TextReader._check_tokenize_status()\n\nFile parsers.pyx:2061, in pandas._libs.parsers.raise_parser_error()\n\nParserError: Error tokenizing data. C error: Expected 4 fields in line 21, saw 6\n\n\n\n\n\n\nSee our solution!\n# Load the GBIF data\ngbif_df = pd.read_csv(\n    gbif_path, \n    delimiter='\\t',\n    index_col='gbifID',\n    usecols=['gbifID', 'decimalLatitude', 'decimalLongitude', 'month'])\ngbif_df.head()\n\n\n\n\n\n\n\n\n\ndecimalLatitude\ndecimalLongitude\nmonth\n\n\ngbifID\n\n\n\n\n\n\n\n4617234711\n43.353010\n-118.97914\n3\n\n\n4835897733\n43.549930\n-115.71172\n5\n\n\n4678582942\n40.362244\n-111.88321\n4\n\n\n4650705779\n38.119060\n-122.95225\n10\n\n\n4687482912\n38.463760\n-105.05151\n10\n\n\n\n\n\n\n\n\n\nConvert the GBIF data to a GeoDataFrame\nTo plot the GBIF data, we need to convert it to a GeoDataFrame first.\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task\n\n\n\n\nReplace your_dataframe with the name of the DataFrame you just got from GBIF\nReplace longitude_column_name and latitude_column_name with column names from your `DataFrame\nRun the code to get a GeoDataFrame of the GBIF data.\n\n\n\n\ngbif_gdf = (\n    gpd.GeoDataFrame(\n        your_dataframe, \n        geometry=gpd.points_from_xy(\n            your_dataframe.longitude_column_name, \n            your_dataframe.latitude_column_name), \n        crs=\"EPSG:4326\")\n    # Select the desired columns\n    [[]]\n)\ngbif_gdf\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[20], line 3\n      1 gbif_gdf = (\n      2     gpd.GeoDataFrame(\n----&gt; 3         your_dataframe, \n      4         geometry=gpd.points_from_xy(\n      5             your_dataframe.longitude_column_name, \n      6             your_dataframe.latitude_column_name), \n      7         crs=\"EPSG:4326\")\n      8     # Select the desired columns\n      9     [[]]\n     10 )\n     11 gbif_gdf\n\nNameError: name 'your_dataframe' is not defined\n\n\n\n\n\nSee our solution!\ngbif_gdf = (\n    gpd.GeoDataFrame(\n        gbif_df, \n        geometry=gpd.points_from_xy(\n            gbif_df.decimalLongitude, \n            gbif_df.decimalLatitude), \n        crs=\"EPSG:4326\")\n    # Select the desired columns\n    [['month', 'geometry']]\n)\ngbif_gdf\n\n\n\n\n\n\n\n\n\nmonth\ngeometry\n\n\ngbifID\n\n\n\n\n\n\n4617234711\n3\nPOINT (-118.97914 43.35301)\n\n\n4835897733\n5\nPOINT (-115.71172 43.54993)\n\n\n4678582942\n4\nPOINT (-111.88321 40.36224)\n\n\n4650705779\n10\nPOINT (-122.95225 38.11906)\n\n\n4687482912\n10\nPOINT (-105.05151 38.46376)\n\n\n...\n...\n...\n\n\n4666761701\n4\nPOINT (-102.40224 35.04218)\n\n\n4823503698\n5\nPOINT (-104.46048 38.57695)\n\n\n4760808865\n6\nPOINT (-96.43833 47.08567)\n\n\n4690775913\n6\nPOINT (-113.22199 53.19315)\n\n\n4762651338\n6\nPOINT (-105.06943 39.42953)\n\n\n\n\n249042 rows × 2 columns",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 3: Species Distribution",
      "Mapping Tasiyagnunpa (Western Meadowlark) migration"
    ]
  },
  {
    "objectID": "notebooks/03-species-distribution/species-distribution.html#count-the-number-of-observations-in-each-ecosystem-during-each-month-of-2023",
    "href": "notebooks/03-species-distribution/species-distribution.html#count-the-number-of-observations-in-each-ecosystem-during-each-month-of-2023",
    "title": "Mapping Tasiyagnunpa (Western Meadowlark) migration",
    "section": "Count the number of observations in each ecosystem, during each month of 2023",
    "text": "Count the number of observations in each ecosystem, during each month of 2023\n\nIdentify the ecoregion for each observation\nYou can combine the ecoregions and the observations spatially using a method called .sjoin(), which stands for spatial join.\n\n\n\n\n\n\n{{&lt; fa glasses large &gt;}} Further reading\n\n\n\nCheck out the geopandas documentation on spatial joins to help you figure this one out. You can also ask your favorite LLM (Large-Language Model, like ChatGPT)\n\n\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task\n\n\n\n\nIdentify the correct values for the how= and predicate= parameters of the spatial join.\nSelect only the columns you will need for your plot.\nRun the code.\n\n\n\n\ngbif_ecoregion_gdf = (\n    ecoregions_gdf\n    # Match the CRS of the GBIF data and the ecoregions\n    .to_crs(gbif_gdf.crs)\n    # Find ecoregion for each observation\n    .sjoin(\n        gbif_gdf,\n        how='', \n        predicate='')\n    # Select the required columns\n    \n)\ngbif_ecoregion_gdf\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[22], line 2\n      1 gbif_ecoregion_gdf = (\n----&gt; 2     ecoregions_gdf\n      3     # Match the CRS of the GBIF data and the ecoregions\n      4     .to_crs(gbif_gdf.crs)\n      5     # Find ecoregion for each observation\n      6     .sjoin(\n      7         gbif_gdf,\n      8         how='', \n      9         predicate='')\n     10     # Select the required columns\n     11     \n     12 )\n     13 gbif_ecoregion_gdf\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/geopandas/geodataframe.py:2195, in GeoDataFrame.sjoin(self, df, *args, **kwargs)\n   2121 def sjoin(self, df, *args, **kwargs):\n   2122     \"\"\"Spatial join of two GeoDataFrames.\n   2123 \n   2124     See the User Guide page :doc:`../../user_guide/mergingdata` for details.\n   (...)\n   2193     sjoin : equivalent top-level function\n   2194     \"\"\"\n-&gt; 2195     return geopandas.sjoin(left_df=self, right_df=df, *args, **kwargs)\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/geopandas/tools/sjoin.py:119, in sjoin(left_df, right_df, how, predicate, lsuffix, rsuffix, **kwargs)\n    116     first = next(iter(kwargs.keys()))\n    117     raise TypeError(f\"sjoin() got an unexpected keyword argument '{first}'\")\n--&gt; 119 _basic_checks(left_df, right_df, how, lsuffix, rsuffix)\n    121 indices = _geom_predicate_query(left_df, right_df, predicate)\n    123 joined = _frame_join(indices, left_df, right_df, how, lsuffix, rsuffix)\n\nFile /usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/geopandas/tools/sjoin.py:158, in _basic_checks(left_df, right_df, how, lsuffix, rsuffix)\n    156 allowed_hows = [\"left\", \"right\", \"inner\"]\n    157 if how not in allowed_hows:\n--&gt; 158     raise ValueError(\n    159         '`how` was \"{}\" but is expected to be in {}'.format(how, allowed_hows)\n    160     )\n    162 if not _check_crs(left_df, right_df):\n    163     _crs_mismatch_warn(left_df, right_df, stacklevel=4)\n\nValueError: `how` was \"\" but is expected to be in ['left', 'right', 'inner']\n\n\n\n\n\nSee our solution!\ngbif_ecoregion_gdf = (\n    ecoregions_gdf\n    # Match the CRS of the GBIF data and the ecoregions\n    .to_crs(gbif_gdf.crs)\n    # Find ecoregion for each observation\n    .sjoin(\n        gbif_gdf,\n        how='inner', \n        predicate='contains')\n    # Select the required columns\n    [['month', 'name']]\n)\ngbif_ecoregion_gdf\n\n\n\n\n\n\n\n\n\nmonth\nname\n\n\necoregion\n\n\n\n\n\n\n57\n6\nThompson-Okanogan Plateau\n\n\n57\n9\nThompson-Okanogan Plateau\n\n\n57\n6\nThompson-Okanogan Plateau\n\n\n57\n6\nThompson-Okanogan Plateau\n\n\n57\n8\nThompson-Okanogan Plateau\n\n\n...\n...\n...\n\n\n2545\n6\nEastern Cascades Slopes and Foothills\n\n\n2545\n6\nEastern Cascades Slopes and Foothills\n\n\n2545\n5\nEastern Cascades Slopes and Foothills\n\n\n2545\n5\nEastern Cascades Slopes and Foothills\n\n\n2545\n4\nEastern Cascades Slopes and Foothills\n\n\n\n\n248059 rows × 2 columns\n\n\n\n\n\nCount the observations in each ecoregion each month\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task:\n\n\n\n\nReplace columns_to_group_by with a list of columns. Keep in mind that you will end up with one row for each group – you want to count the observations in each ecoregion by month.\nSelect only month/ecosystem combinations that have more than one occurrence recorded, since a single occurrence could be an error.\nUse the .groupby() and .mean() methods to compute the mean occurrences by ecoregion and by month.\nRun the code – it will normalize the number of occurrences by month and ecoretion.\n\n\n\n\noccurrence_df = (\n    gbif_ecoregion_gdf\n    # For each ecoregion, for each month...\n    .groupby(columns_to_group_by)\n    # ...count the number of occurrences\n    .agg(occurrences=('name', 'count'))\n)\n\n# Get rid of rare observations (possible misidentification?)\noccurrence_df = occurrence_df[...]\n\n# Take the mean by ecoregion\nmean_occurrences_by_ecoregion = (\n    occurrence_df\n    ...\n)\n# Take the mean by month\nmean_occurrences_by_month = (\n    occurrence_df\n    ...\n)\n\n# Normalize the observations by the monthly mean throughout the year\noccurrence_df['norm_occurrences'] = (\n    occurrence_df.occurrences \n    / mean_occurrences_by_ecoregion\n    / mean_occurrences_by_month\n)\noccurrence_df\n\n\n  Cell In[24], line 14\n    occurrence_df\n    ^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\n\n\n\n\n\n\nSee our solution!\noccurrence_df = (\n    gbif_ecoregion_gdf\n    # For each ecoregion, for each month...\n    .groupby(['ecoregion', 'month'])\n    # ...count the number of occurrences\n    .agg(occurrences=('name', 'count'))\n)\n\n# Get rid of rare observation noise (possible misidentification?)\noccurrence_df = occurrence_df[occurrence_df.occurrences&gt;1]\n\n# Take the mean by ecoregion\nmean_occurrences_by_ecoregion = (\n    occurrence_df\n    .groupby(['ecoregion'])\n    .mean()\n)\n# Take the mean by month\nmean_occurrences_by_month = (\n    occurrence_df\n    .groupby(['month'])\n    .mean()\n)\n\n# Normalize the observations by the monthly mean throughout the year\noccurrence_df['norm_occurrences'] = (\n    occurrence_df\n    / mean_occurrences_by_ecoregion\n    / mean_occurrences_by_month\n)\noccurrence_df\n\n\n\n\n\n\n\n\n\n\noccurrences\nnorm_occurrences\n\n\necoregion\nmonth\n\n\n\n\n\n\n57\n3\n132\n0.003020\n\n\n4\n397\n0.004641\n\n\n5\n660\n0.004941\n\n\n6\n481\n0.005170\n\n\n7\n182\n0.003507\n\n\n...\n...\n...\n...\n\n\n2545\n8\n76\n0.003036\n\n\n9\n63\n0.002618\n\n\n10\n78\n0.002695\n\n\n11\n45\n0.001367\n\n\n12\n61\n0.001663\n\n\n\n\n983 rows × 2 columns",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 3: Species Distribution",
      "Mapping Tasiyagnunpa (Western Meadowlark) migration"
    ]
  },
  {
    "objectID": "notebooks/03-species-distribution/species-distribution.html#plot-the-tasiyagnunpa-observations-by-month",
    "href": "notebooks/03-species-distribution/species-distribution.html#plot-the-tasiyagnunpa-observations-by-month",
    "title": "Mapping Tasiyagnunpa (Western Meadowlark) migration",
    "section": "Plot the Tasiyagnunpa observations by month",
    "text": "Plot the Tasiyagnunpa observations by month\n\n\n\n\n\n\n{{&lt; fa keyboard large &gt;}} Your task\n\n\n\n\nIf applicable, replace any variable names with the names you defined previously.\nReplace column_name_used_for_ecoregion_color and column_name_used_for_slider with the column names you wish to use.\nCustomize your plot with your choice of title, tile source, color map, and size.\n\n\n\n\n# Join the occurrences with the plotting GeoDataFrame\noccurrence_gdf = ecoregions_plot_gdf.join(occurrence_df)\n\n# Get the plot bounds so they don't change with the slider\nxmin, ymin, xmax, ymax = occurrence_gdf.total_bounds\n\n# Plot occurrence by ecoregion and month\nmigration_plot = (\n    occurrence_gdf\n    .hvplot(\n        c=column_name_used_for_shape_color,\n        groupby=column_name_used_for_slider,\n        # Use background tiles\n        geo=True, crs=ccrs.Mercator(), tiles='CartoLight',\n        title=\"Your Title Here\",\n        xlim=(xmin, xmax), ylim=(ymin, ymax),\n        frame_height=600,\n        widget_location='bottom'\n    )\n)\n\n# Save the plot\nmigration_plot.save('migration.html', embed=True)\n\n# Show the plot\nmigration_plot\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[26], line 11\n      5 xmin, ymin, xmax, ymax = occurrence_gdf.total_bounds\n      7 # Plot occurrence by ecoregion and month\n      8 migration_plot = (\n      9     occurrence_gdf\n     10     .hvplot(\n---&gt; 11         c=column_name_used_for_shape_color,\n     12         groupby=column_name_used_for_slider,\n     13         # Use background tiles\n     14         geo=True, crs=ccrs.Mercator(), tiles='CartoLight',\n     15         title=\"Your Title Here\",\n     16         xlim=(xmin, xmax), ylim=(ymin, ymax),\n     17         frame_height=600,\n     18         widget_location='bottom'\n     19     )\n     20 )\n     22 # Save the plot\n     23 migration_plot.save('migration.html', embed=True)\n\nNameError: name 'column_name_used_for_shape_color' is not defined\n\n\n\n\n\nSee our solution!\n# Join the occurrences with the plotting GeoDataFrame\noccurrence_gdf = ecoregions_plot_gdf.join(occurrence_df)\n\n# Get the plot bounds so they don't change with the slider\nxmin, ymin, xmax, ymax = occurrence_gdf.total_bounds\n\n# Define the slider widget\nslider = pn.widgets.DiscreteSlider(\n    name='month', \n    options={calendar.month_name[i]: i for i in range(1, 13)}\n)\n\n# Plot occurrence by ecoregion and month\nmigration_plot = (\n    occurrence_gdf\n    .hvplot(\n        c='norm_occurrences',\n        groupby='month',\n        # Use background tiles\n        geo=True, crs=ccrs.Mercator(), tiles='CartoLight',\n        title=\"Tasiyagnunpa migration\",\n        xlim=(xmin, xmax), ylim=(ymin, ymax),\n        frame_height=600,\n        colorbar=False,\n        widgets={'month': slider},\n        widget_location='bottom'\n    )\n)\n\n# Save the plot\nmigration_plot.save('migration.html', embed=True)\n\n# Show the plot\nmigration_plot\n\n\n\n\n\n\n\n\n\n{{&lt; fa pepper-hot large &gt;}} Want an EXTRA CHALLENGE?\n\n\n\nNotice that the month slider displays numbers instead of the month name. Use pn.widgets.DiscreteSlider() with the options= parameter set to give the months names. You might want to try asking ChatGPT how to do this, or look at the documentation for pn.widgets.DiscreteSlider(). This is pretty tricky!",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 3: Species Distribution",
      "Mapping Tasiyagnunpa (Western Meadowlark) migration"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/03-html.html",
    "href": "pages/03-git-github/03-github-portfolio/03-html.html",
    "title": "Customize your website content",
    "section": "",
    "text": "Most web pages are built using three key technologies:\n\nHyper-Text Markup Language (HTML) includes and structures the content\nCascading Style Sheets (CSS) controls how the page looks\nJavascript (JS) controls what the page does\n\nWhen using GitHub Pages, you can rely on GitHub to translate Markdown to HTML before putting it on the web using a system called Jekyll. You can see the result by:\n\nNavigate to your portfolio page on the internet\nRight-click anywhere on the page\nSelect an option like Inspect or Web Developer Tools, depending on your browser.\n\nYou should now see the source code for your webpage in a new panel. What do you notice about your content? How is it different from what you wrote?\n\n\n\nWeb developer tools\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can also control CSS and JS to a limited extent on GitHub Pages. However, we recommend sticking with the CSS and JS supplied by a Jekyll theme created by a designer. It’s hard to make a website that looks good from scratch. We’ll get into how to add a theme using Jekyll later on.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 3: Custom content"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/03-html.html#the-building-blocks-of-the-web",
    "href": "pages/03-git-github/03-github-portfolio/03-html.html#the-building-blocks-of-the-web",
    "title": "Customize your website content",
    "section": "",
    "text": "Most web pages are built using three key technologies:\n\nHyper-Text Markup Language (HTML) includes and structures the content\nCascading Style Sheets (CSS) controls how the page looks\nJavascript (JS) controls what the page does\n\nWhen using GitHub Pages, you can rely on GitHub to translate Markdown to HTML before putting it on the web using a system called Jekyll. You can see the result by:\n\nNavigate to your portfolio page on the internet\nRight-click anywhere on the page\nSelect an option like Inspect or Web Developer Tools, depending on your browser.\n\nYou should now see the source code for your webpage in a new panel. What do you notice about your content? How is it different from what you wrote?\n\n\n\nWeb developer tools\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can also control CSS and JS to a limited extent on GitHub Pages. However, we recommend sticking with the CSS and JS supplied by a Jekyll theme created by a designer. It’s hard to make a website that looks good from scratch. We’ll get into how to add a theme using Jekyll later on.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 3: Custom content"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/03-html.html#use-html-to-add-features-that-arent-available-in-markdown",
    "href": "pages/03-git-github/03-github-portfolio/03-html.html#use-html-to-add-features-that-arent-available-in-markdown",
    "title": "Customize your website content",
    "section": "Use HTML to add features that aren’t available in Markdown",
    "text": "Use HTML to add features that aren’t available in Markdown\nWhen creating your webpage, you might want to do a couple of things with your content that most types of Markdown can’t do, such as:\n\nSpecify the size of an image\nControl whether links open up in a new tab\nEmbed videos and other web content\nChange colors, fonts, or font sizes in one section of your page\n\nHTML (Hyper-Text Markup Language), does have the ability to do all those things and more.\n\nMake sure to format your HTML code so that it is readable\nOne great thing about Markdown is that it is both human-readable and machine-readable. It’s a little harder to tell what is going on with HTML, especially if it is formatted poorly. For example, take a look at some Markdown and its equivalent in HTML. Unlike Markdown, the computer doesn’t care how we use whitespace when formatting HTML. We can make HTML easier to read by adding whitespace and new lines:\n\nMarkdownMessy HTML (Don’t do this!)Cleaner HTML\n\n\n1# A fabulous Earth Data Science Portfolio\n\n2![Super-cool satellite imagery](/img/cool_satellite_image.jpeg)\n\nSome text and [a link](https://www.my_link.org) and:\n\n  * A\n  * Bulleted\n  * List\n\n1\n\nThe will be a level 1 header because it begins with one #\n\n2\n\nThis will be an image since it starts with a !\n\n\n\n\n&lt;h1&gt;A fabulous Earth Data Science Portfolio&lt;/h1&gt;&lt;img \nsrc=\"/img/cool_satellite_image.jpeg\" alt-text=\"Super-cool satellite imagery\"&gt;\n&lt;p&gt;Some text and &lt;a \nhref=\"https://www.my_link.org\"&gt;a link&lt;/a&gt; \nand:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A&lt;/li&gt;&lt;li&gt;Bulleted\n&lt;/li&gt;&lt;li&gt;List&lt;/li&gt;&lt;/ul&gt;\n\n\n1&lt;h1&gt;A fabulous Earth Data Science Portfolio&lt;/h1&gt;\n\n2&lt;!-- Comments help the reader understand your code --&gt;\n&lt;img \n  src=\"/img/cool_satellite_image.jpeg\" \n3  alt=\"Super-cool satellite imagery\" /&gt;\n\n&lt;p&gt;\n  Some text and &lt;a href=\"https://www.my_link.org\"&gt;a link&lt;/a&gt; \n  and:\n&lt;/p&gt;\n\n&lt;ul&gt;\n    &lt;li&gt;A&lt;/li&gt;\n    &lt;li&gt;Bulleted&lt;/li&gt;\n    &lt;li&gt;List&lt;/li&gt;\n&lt;/ul&gt;\n\n1\n\nThis is a level 1 header, since it is surrounded by h1 tags.\n\n2\n\nComments won’t appear on your web page\n\n3\n\nThe img tag will be an image.\n\n\n\n\n\n\n\nHTML syntax for Markdown users\nEvery coding language has some special characters and structures, known as the syntax. When you render or run code, the syntax gets interpreted into some kind of behavior. For example, in Markdown, the syntax # gets interpreted as the start of a level 1 header.\nHTML is less human-readable than Markdown. To use it effectively, you will need to understand some key vocabulary about the syntactic elements of HTML.\n\nTags\n\n\n\n\n\n\n\nSpeak Code\n\n\n\nRemember that the &lt; and &gt; symbols are usually used to surround text you should replace with something applicable to you and your project. There’s a BIG exception when it comes to building websites – &lt; and &gt; are key special characters if you are using HTML, the markup language used on most websites. So, if the code sample is HTML, you should leave the angle brackets &lt; and &gt; in.\n\nNotice that most elements are surrounded by tags enclosed in angle brackets (&lt; and &gt;). For example, when we include a header 1, we do that with the following code:\n1&lt;h1&gt;\n2  A fabulous Earth Data Science Portfolio\n3&lt;/h1&gt;\n\n1\n\nStart with the opening tag for h1 (header level 1), then\n\n2\n\nPlace the text of the header in between the tags.\n\n3\n\nEnd with the closing tag, which match the opening tag plus a slash (/)\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf there is no text that needs to go between two HTML tags, you don’t need a closing tag. Instead, you can end the opening tag with /&gt; to indicate that there’s no content. For example, take another look at the image HTML code:\n&lt;img \n  src=\"/img/cool_satellite_image.jpeg\" \n  alt=\"Super-cool satellite imagery\" /&gt;\n\n\n\n\nParameters\nIn addition to marking the beginning and end of HTML elements, tags can contain addition information about how to display their contents. This extra information is known as parameters. For example, let’s revisit the code above for an HTML link, which contains the href parameter:\n1&lt;a href=\"https://www.my_link.org\"&gt;\n  a link\n&lt;/a&gt;\n\n1\n\nParameters are included inside the opening tag. The parameter name (href) must be followed by and equals sign =, and the parameter value (https://www.my_link.org) must be surrounded by quotation marks.\n\n\n\n\n\nInclude HTML directly in Markdown\nYou can add HTML elements into your Markdown documents. There is no need when using GitHub Pages to write entire documents in HTML; you can directly substitute HTML elements for Markdown elements where needed. For example,\n\n\nAdjust the size of images\nSay you have written the following Markdown to display an image:\n![Super-cute pika!](/img/pika.jpg)\n\n\nImage source: Wikipedia\n\nUnfortunately, the image is taking up the entire width of the section. You can’t adjust the size with GitHub Markdown alone, but you can replace the image with HTML and control the width:\n&lt;img \n  src=\"/img/pika.jpg\" \n  alt=\"Super-cute pika!\" \n  width=\"25%\"&gt;\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you set both the width and the height of an image, your image will become distorted:\n&lt;img \n  src=\"/img/pika.jpg\" \n  alt=\"Super-cute pika!\" \n  height=\"100px\" \n  width=\"400px\"&gt;\n\n\n\nWhen setting image height and width, there are different units you can use:\n\n\n\n\n\n\n\nUnit\nMeaning\n\n\n\n\npx\nA pixel is the smallest item that can be displayed on your screen\n\n\nem or rem\nThese units are relative to your font size (e.g. the width of an m)\n\n\n%\nA percentage of the element that contains the image\n\n\n\nWhen using px, keep in mind that others may be viewing your webpage on different devices (e.g. phone vs. computer). px units are pegged to the resolution of the screen, so this can result in vastly different sizes on different devices. Furthermore, rem measurements will change if the viewer zooms in or out of the page in their browser, making them more accessible.\n\n\n\n\n\n\nTip\n\n\n\nYou can simulate what your webpage will look like on another device using the Web Developer Tools. Usually there’s a button that looks like a screen in the upper right.\n\n\n\nWeb developer tools with the device simulator highlighted\n\n\n\n\n\n\nOpen external links in a new tab\nWhen you are linking to someone else’s webpage, often you want that page to open in a new tab or window so your reader doesn’t leave your webpage.\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that some web designers and readers don’t like this behavior and would prefer that the reader decide for themselves whether they open a new tab or not. But it’s a pretty widespread practice, so it’s up to you how you want your webpage to work.\n\nThere’s no way to do this in most flavors of Markdown, but if you write your link in HTML you can at a target=\"_blank\" parameter:\n&lt;a \n  href=\"https://www.my_link.org\"\n  target=\"_blank\"&gt;\n  a link\n&lt;/a&gt; \n\n\nEmbedding content from other webpages\nMarkdown is great for text and images, but what if you want to content that is hosted elsewhere, like a video? HTML lets you load content from other webpages (also known as embedding content) using an element called an iframe:\n&lt;iframe \n  width=\"467\" height=\"831\" \n  src=\"https://www.youtube.com/embed/Oly8f4h5C78\" \n  title=\"Natural Habitat Shorts- Chipmunks have cheek pouches used to store food. 🐿🥜\" \n  frameborder=\"0\" \n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" \n  allowfullscreen&gt;\n&lt;/iframe&gt;\n\n\nUsually the website that hosts your video will already have embed code prepared for you. For example, on YouTube you can find the embed code below the video:\n\n\nStyling text\nStyle on a webpage refers to how the page looks. For example, you might want to change colors, fonts, or spacing on your page. Usually this would be done with CSS or with pre-styled theme elements. However, if you doing something small, you can use the style parameter in an HTML tag, as in the following examples:\n\n\n\n\n\n\nChange the \n&lt;span style=\"color: red; font-size: 2rem\"&gt; \n  color and font size\n&lt;/span&gt;.\nChange the  color and font size.\n\n\n\n\n\n\nTip\n\n\n\nWe are using the span tag here instead of the p (paragraph) tag, so that HTML will not put the text on a new line.\n\n\n\n\n\n\n\n\n\n\n\nAdd a border to an image:\n\n&lt;img \n  src=\"/img/cool_satellite_image.jpeg\" \n  alt=\"Super-cool satellite imagery\" \n  height=\"100rem\"\n  style=\"border: dashed 5px blue;\"&gt;",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 3: Custom content"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/00-introduction.html",
    "href": "pages/03-git-github/03-github-portfolio/00-introduction.html",
    "title": "Join the Open Earth Data Science community online",
    "section": "",
    "text": "The internet has revolutionized science publishing. For example, most published scientific papers are now made freely available online within one year (Randall Munroe 2013):\n\n\n\nThe Rise of Open Science: The accelerating pace of scientific publishing and the rise of open access, as depicted by xkcd.com cartoonist Randall Munroe. Open access reached a tipping point in 2011, when more than half of new research became available freely online.\n\n\nIt’s not just peer-reviewed publications that have changed – scientists all over the world now use websites, blogs, and social media to discuss, communicate, and publicize their work. The internet is also a great way to transparently involve your community in your research.\n\n\n\n\n\n\nImportant\n\n\n\nNot all science has to be open! It’s important to think about the impacts of publishing your work on people and communities wherever you are studying, and also honor principles data sovereignty. We will talk about some ways to publish your work while omitting or obscuring sensitive details, but for now make sure that you and your mentors are comfortable before putting your work on the internet.\n\n\nThere are lots of tools available for creating free websites. We, as Earth and Environmental Data Scientists, like to use a platform called GitHub Pages for a couple of reasons:\n\nIt’s completely free to use, event for larger websites (like this one!).\nIt is a feature of the code collaboration website GitHub, which is already where most programmers and scientists keep their code. Keeping our websites on GitHub also means that we can collaborate on and discuss them online, the same way we would any other code.\nIt can automatically build an attractive website using text-based, human-readable tools.\nIt can automatically incorporate the plots and maps generated by code.\nThough GitHub itself is not open source software (it’s owned by Microsoft), Pages is built on open-source tools. This means that if for some reason the availability or pricing structure ever changes we could download the code and put the website up somewhere else.\n\n\n\n\n\n\n\nCheck out our explainer video to learn more about what a personal portfolio webpage can do for you, and see some examples from previous students!\n\n \n\nINTRO: Portfolio pages by ESIIL\n\n\n\nIn the following lessons, you will learn how to create a personal portfolio webpage and publish it for free using GitHub Pages.\n\n\n\n\n\n\n\n\n\n\nCreate your own portfolio webpage\n\n\nDocument and share your work\n\n\nShow potential employers and collaborators what you can do, and share your work! In this activity, you will create a personal portfolio webpage. You’ll use this webpage to share some biographical information and a photo of yourself. You can then update your webpage with links to work that you complete. \n\n\n\n\n\nNate Quarderer, Elsa Culler\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nAdd images to your portfolio\n\n\nAs they say, a picture’s worth 1000 words\n\n\nEffective scientific communication is often built on visual evidence, so it’s important to be able to include photographs, figures, and maps into your webpages. \n\n\n\n\n\nNate Quarderer, Elsa Culler\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nCustomize your website content\n\n\nGet started with HTML\n\n\nMarkdown is nice because it is easy to read, and lets us get started building websites quickly. But, it can’t do everything! Adding Hyper-Text Markup Language (HTML) will let you include multi-media materials and customize how your page looks and behaves. \n\n\n\n\n\nNate Quarderer, Elsa Culler\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nSpruce up your website\n\n\nGet started with Jekyll themes\n\n\nIt can be challenging to build an attractive website from scratch. Fortunately, many web designers have created themes to make any website look great. \n\n\n\n\n\nElsa Culler, Nate Quarderer\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nAdd a map to your website\n\n\nGet started with maps\n\n\nAs Earth and Environmental Data Scientists, we know places are important. In this activity, you will make your first map in Python, and use it to tell the story of where you come from and what places are important to you. \n\n\n\n\n\nNate Quarderer, Elsa Culler\n\n\n6 min\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\nReferences\n\nRandall Munroe. 2013. “The Rise of Open Access.” Science 342 (6154): 58–59. https://www.science.org/doi/10.1126/science.342.6154.58.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "Join the Open Earth Data Science community online"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html",
    "href": "notebooks/01-climate/climate.html",
    "title": "Climate Coding Challenge",
    "section": "",
    "text": "format: ipynb: output-file: ‘Climate Coding Challenge, Part 1!’",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#what-the-fork-who-wrote-this",
    "href": "notebooks/01-climate/climate.html#what-the-fork-who-wrote-this",
    "title": "Climate Coding Challenge",
    "section": "What the fork?! Who wrote this?",
    "text": "What the fork?! Who wrote this?\nBelow is a scientific Python workflow. But something’s wrong – The code won’t run! Your task is to follow the instructions below to clean and debug the Python code below so that it runs.\n\n\n\n\n\n\nTip\n\n\n\nDon’t worry if you can’t solve every bug right away. We’ll get there! If you are working on one bug for more than about 10 minutes, it’s time to ask for help.\n\n\nAt the end, you’ll repeat the workflow for a location and measurement of your choosing.\nAlright! Let’s clean up this code.\n\nformat: ipynb: output-file: ‘Climate Coding Challenge, Part 2!’",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#python-packages-let-you-use-code-written-by-experts-around-the-world",
    "href": "notebooks/01-climate/climate.html#python-packages-let-you-use-code-written-by-experts-around-the-world",
    "title": "Climate Coding Challenge",
    "section": "Python packages let you use code written by experts around the world",
    "text": "Python packages let you use code written by experts around the world\nBecause Python is open source, lots of different people and organizations can contribute (including you!). Many contributions are in the form of packages which do not come with a standard Python download.\n\n\n\n\n\n\nRead More: Packages need to be installed and imported.\n\n\n\nLearn more about using Python packages. How do you find and use packages? What is the difference between installing and importing packages? When do you need to do each one? This article on Python packages will walk you through the basics.\n\n\nIn the cell below, someone was trying to import the pandas package, which helps us to work with tabular data such as comma-separated value or csv files.\n\n\n\n\n\n\nTry It: Import a package\n\n\n\n\nCorrect the typo below to properly import the pandas package under its alias pd.\nRun the cell to import pandas\n\n\n\n\n# Import pandas\nimport pandsa as pd\n\n\n\nSee our solution!\n# Import pandas\nimport pandas as pd",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#download-the-practice-data",
    "href": "notebooks/01-climate/climate.html#download-the-practice-data",
    "title": "Climate Coding Challenge",
    "section": "Download the practice data",
    "text": "Download the practice data\nNext, lets download some climate data from Rapid City, SD to practice with. We keep our practice data on GitHub, so that we can check that it still works and make sure it looks just like the data you would download from the original source.\n\n\n\n\n\n\nUsing online climate data\n\n\n\nDo you want to download your own climate data from a place of your choosing? We think the sample data we’ve provided is helpful for learning, but hopefully you have some other places and times you want data from. Learn how to modify your NCEI data download in our NCEI Data Library entry.\n\n\nThe cell below contains the URL for the data you will use in this part of the notebook. There are two things to notice about the URL code:\n\nIt is surrounded by quotes – that means Python will interpret it as a string, or text, type, which makes sense for a URL.\nThe URL is too long to display as one line on most screens. We’ve put parentheses around it so that we can easily split it into multiple lines by writing two strings – one on each line.\n\nHowever, we still have a problem - we can’t get the URL back later on because it isn’t saved in a variable. In other words, we need to give the url a name so that we can request in from Python later (sadly, Python has no ‘hey what was that thingy I typed yesterday?’ function).\n\n\n\n\n\n\nRead More: Names/variables in Python\n\n\n\nOne of the most common challenges for new programmers is making sure that your results are stored so you can use them again. In Python, this is called naming, or saving a variable. Learn more in this hands-on activity on using variables from our learning portal.\n\n\n\n\n\n\n\n\nTry It: Save the URL for later\n\n\n\n\nPick an expressive variable name for the URL.\nClick on the Jupyter tab in the console panel at the bottom of VSCode to see all your variables. Your new url variable will not be there until you define it and run the code.\nAt the end of the cell where you define your url variable, call your variable (type out its name) so it can be tested.\n\n\n\n\n(\n    'https://github.com/cu-esiil-edu/esiil-learning-portal'\n    '/releases/download/data-release/climate-foundations-data.csv'\n)\n\n\n\nSee our solution!\nncei_url = (\n    'https://github.com/cu-esiil-edu/esiil-learning-portal'\n    '/releases/download/data-release/climate-foundations-data.csv'\n)\nncei_url\n\n\n'https://github.com/cu-esiil-edu/esiil-learning-portal/releases/download/data-release/climate-foundations-data.csv'\n\n\nThe pandas library you imported can download data from the internet directly into a type of Python object called a DataFrame. In the code cell below, you can see an attempt to do just this. But there are some problems…\n\n\n\n\n\n\nTry It: Fix some code!\n\n\n\n\nLeave a space between the # and text in the comment and try making the comment more informative\nMake any changes needed to get this code to run. HINT: The my_url variable doesn’t exist - you need to replace it with the variable name you chose.\nModify the .read_csv() statement to include the following parameters:\n\nindex_col='DATE' – this sets the DATE column as the index. Needed for subsetting and resampling later on\nparse_dates=True – this lets python know that you are working with time-series data, and values in the indexed column are date time objects\nna_values=['NaN'] – this lets python know how to handle missing values\n\nClean up the code by using expressive variable names, expressive column names, PEP-8 compliant code, and descriptive comments\n\n\n\n\nMake sure to call your DataFrame by typing it’s name as the last line of your code cell Then, you will be able to run the test cell below and find out if your answer is correct.\n\n\nclimate_df = pd.read_csv(\n    my_url,\n    index_col='something')\nclimate_df\n\n\n\nSee our solution!\n# Download the climate data\nclimate_df = pd.read_csv(\n    ncei_url,\n    index_col='DATE',\n    parse_dates=True,\n    na_values=['NaN'])\nclimate_df\n\n\n\n\n\n\n\n\n\nSTATION\nPRCP\nTOBS\n\n\nDATE\n\n\n\n\n\n\n\n1893-10-01\nUSC00050848\n0.94\nNaN\n\n\n1893-10-02\nUSC00050848\n0.00\nNaN\n\n\n1893-10-03\nUSC00050848\n0.00\nNaN\n\n\n1893-10-04\nUSC00050848\n0.04\nNaN\n\n\n1893-10-05\nUSC00050848\n0.00\nNaN\n\n\n...\n...\n...\n...\n\n\n2023-09-26\nUSC00050848\n0.00\n74.0\n\n\n2023-09-27\nUSC00050848\n0.00\n69.0\n\n\n2023-09-28\nUSC00050848\n0.00\n73.0\n\n\n2023-09-29\nUSC00050848\n0.00\n66.0\n\n\n2023-09-30\nUSC00050848\n0.00\n78.0\n\n\n\n\n45971 rows × 3 columns\n\n\n\n\nHINT: Check out the type() function below - you can use it to check that your data is now in DataFrame type object\n\n\n# Check that the data was imported into a pandas DataFrame\ntype(climate_df)",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#clean-up-your-dataframe",
    "href": "notebooks/01-climate/climate.html#clean-up-your-dataframe",
    "title": "Climate Coding Challenge",
    "section": "Clean up your DataFrame",
    "text": "Clean up your DataFrame\n\n\n\n\n\n\nTry It: Get rid of unwanted columns\n\n\n\nYou can use double brackets ([[ and ]]) to select only the columns that you want from your DataFrame:\n\nChange some_column_name to the Precipitation column name and another_column_name to the Observed Temperature column name.\n\n\n\n\n\n\n\nWarning\n\n\n\nColumn names are text values, not variable names, so you need to put them in quotes!\n\n\n\n\n\nMake sure to call your DataFrame by typing it’s name as the last line of your code cell Then, you will be able to run the test cell below and find out if your answer is correct.\n\n\nclimate_df = climate_df[['some_column_name', 'another_column_name']]\nclimate_df\n\n\n\nSee our solution!\n# Clean up the DataFrame\nclimate_df = climate_df[['PRCP', 'TOBS']]\nclimate_df\n\n\n\n\n\n\n\n\n\nPRCP\nTOBS\n\n\nDATE\n\n\n\n\n\n\n1893-10-01\n0.94\nNaN\n\n\n1893-10-02\n0.00\nNaN\n\n\n1893-10-03\n0.00\nNaN\n\n\n1893-10-04\n0.04\nNaN\n\n\n1893-10-05\n0.00\nNaN\n\n\n...\n...\n...\n\n\n2023-09-26\n0.00\n74.0\n\n\n2023-09-27\n0.00\n69.0\n\n\n2023-09-28\n0.00\n73.0\n\n\n2023-09-29\n0.00\n66.0\n\n\n2023-09-30\n0.00\n78.0\n\n\n\n\n45971 rows × 2 columns\n\n\n\n\nformat: ipynb: output-file: ‘Climate Coding Challenge, Part 3!’",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#use-labels-to-keep-track-of-units-for-you-and-your-collaborators",
    "href": "notebooks/01-climate/climate.html#use-labels-to-keep-track-of-units-for-you-and-your-collaborators",
    "title": "Climate Coding Challenge",
    "section": "Use labels to keep track of units for you and your collaborators",
    "text": "Use labels to keep track of units for you and your collaborators\nOne way to keep track of your data’s units is to include the unit in data labels. In the case of a DataFrame, that usually means the column names.\n\n\n\n\n\n\nTry It: Add units to your column name\n\n\n\nA big part of writing expressive code is descriptive labels. Let’s rename the columns of your dataframe to include units. Complete the following steps:\n\nReplace dataframe with the name of your DataFrame, and dataframe_units with an expressive new name.\nCheck out the documentation for GCHNd data. We downloaded data with “standard” units; find out what that means for both temperature and precipitation.\nReplace 'TOBS_UNIT' and 'PRCP_UNIT' with column names that reference the correct unit for each.\n\n\n\n\ndataframe_units = dataframe.rename(columns={\n    'TOBS': 'TOBS_UNIT',\n    'PRCP': 'PRCP_UNIT'\n})\n\ndataframe\n\n\n\nSee our solution!\nclimate_u_df = climate_df.rename(columns={\n    'TOBS': 'temp_f',\n    'PRCP': 'precip_in'\n})\nclimate_u_df\n\n\n\n\n\n\n\n\n\nprecip_in\ntemp_f\n\n\nDATE\n\n\n\n\n\n\n1893-10-01\n0.94\nNaN\n\n\n1893-10-02\n0.00\nNaN\n\n\n1893-10-03\n0.00\nNaN\n\n\n1893-10-04\n0.04\nNaN\n\n\n1893-10-05\n0.00\nNaN\n\n\n...\n...\n...\n\n\n2023-09-26\n0.00\n74.0\n\n\n2023-09-27\n0.00\n69.0\n\n\n2023-09-28\n0.00\n73.0\n\n\n2023-09-29\n0.00\n66.0\n\n\n2023-09-30\n0.00\n78.0\n\n\n\n\n45971 rows × 2 columns",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#for-scientific-applications-it-is-often-useful-to-have-values-in-metric-units",
    "href": "notebooks/01-climate/climate.html#for-scientific-applications-it-is-often-useful-to-have-values-in-metric-units",
    "title": "Climate Coding Challenge",
    "section": "For scientific applications, it is often useful to have values in metric units",
    "text": "For scientific applications, it is often useful to have values in metric units\n\n\n\n\n\n\nTry It: Convert units\n\n\n\nThe code below attempts to convert the data to Celcius, using Python mathematical operators, like +, -, *, and /. Mathematical operators in Python work just like a calculator, and that includes using parentheses to designat the order of operations. The equation for converting Fahrenheit temperature to Celcius is:\n\\[\nT_C = (T_F - 32) * \\frac{5}{9}\n\\]\nThis code is not well documented and doesn’t follow PEP-8 guidelines, which has caused the author to miss an important error!\nComplete the following steps:\n\nReplace dataframe with the name of your DataFrame.\nReplace 'old_temperature' with the column name you used; Replace 'new_temperature' with an expressive column name.\nTHERE IS AN ERROR IN THE CONVERSION MATH - Fix it!\n\n\n\n\ndataframe_units['new_temperature']= dataframe_units['old_temperature']-32*5/9\ndataframe_units\n\n\n\nSee our solution!\nclimate_u_df['temp_c'] = (climate_u_df['temp_f'] - 32) * 5 / 9\n\nclimate_u_df\n\n\n\n\n\n\n\n\n\nprecip_in\ntemp_f\ntemp_c\n\n\nDATE\n\n\n\n\n\n\n\n1893-10-01\n0.94\nNaN\nNaN\n\n\n1893-10-02\n0.00\nNaN\nNaN\n\n\n1893-10-03\n0.00\nNaN\nNaN\n\n\n1893-10-04\n0.04\nNaN\nNaN\n\n\n1893-10-05\n0.00\nNaN\nNaN\n\n\n...\n...\n...\n...\n\n\n2023-09-26\n0.00\n74.0\n23.333333\n\n\n2023-09-27\n0.00\n69.0\n20.555556\n\n\n2023-09-28\n0.00\n73.0\n22.777778\n\n\n2023-09-29\n0.00\n66.0\n18.888889\n\n\n2023-09-30\n0.00\n78.0\n25.555556\n\n\n\n\n45971 rows × 3 columns\n\n\n\n\n\n\n\n\n\nLooking for an Extra Challenge?\n\n\n\nUsing the code below as a framework, write and apply a function that converts to Celcius. You should also rewrite this function name to be more expressive.\ndef convert(temperature):\n    \"\"\"Convert temperature to Celcius\"\"\"\n    return temperature # Put your equation in here\n\ndataframe['TOBS_C'] = dataframe['TOBS'].apply(convert)\n\n\n\nformat: ipynb: output-file: ‘Climate Coding Challenge, Part 4!’",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#plot-the-precpitation-column-prcp-vs-time-to-explore-the-data",
    "href": "notebooks/01-climate/climate.html#plot-the-precpitation-column-prcp-vs-time-to-explore-the-data",
    "title": "Climate Coding Challenge",
    "section": "Plot the precpitation column (PRCP) vs time to explore the data",
    "text": "Plot the precpitation column (PRCP) vs time to explore the data\nPlotting in Python is easy, but not quite this easy:\n\nclimate_df.plot()\n\nLooks like we have both precipitation and temperature on the same plot, and it’s hard to see what it is because it’s missing labels!\n\n\n\n\n\n\nLabel your plot\n\n\n\n\n\n\nSource: https://xkcd.com/833\n\n\nMake sure each plot has:\n\nA title that explains where and when the data are from\nx- and y- axis labels with units where appropriate\nA legend where appropriate\n\n\n\nWhen plotting in Python, you’ll always need to add some instructions on labels and how you want your plot to look.\n\n\n\n\n\n\nTry It: Plot your data\n\n\n\n\nChange dataframe to your DataFrame name.\nChange y= to the name of your observed temperature column name.\nUse the title, ylabel, and xlabel parameters to add key text to your plot.\nAdjust the size of your figure using figsize=(x,y) where x is figure width and y is figure height\n\n\nHINT: labels have to be a type in Python called a string. You can make a string by putting quotes around your label, just like the column names in the sample code (eg y='TOBS').\n\n\n\n\n# Plot the data using .plot\nclimate_df.plot(\n    y='the_precipitation_column',\n    title='Title Goes Here',\n    xlabel='Horizontal Axis Label Goes Here',\n    ylabel='Vertical Axis Label Goes Here')\n\n\n\nSee our solution!\n# Plot the data using .plot\nclimate_df.plot(\n    y='TOBS',\n    title='Daily Temperature in Boulder, CO',\n    xlabel='Date',\n    ylabel='Temperature ($^\\circ$F)')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooking for an Extra Challenge?\n\n\n\nThere are many other things you can do to customize your plot. Take a look at the pandas plotting galleries and the documentation of plot to see if there’s other changes you want to make to your plot. Some possibilities include:\n\nRemove the legend since there’s only one data series\nIncrease the figure size\nIncrease the font size\nChange the colors\nUse a bar graph instead (usually we use lines for time series, but since this is annual it could go either way)\nAdd a trend line\n\nNot sure how to do any of these? Try searching the internet, or asking an AI!",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#clean-up-time-series-plots-by-resampling",
    "href": "notebooks/01-climate/climate.html#clean-up-time-series-plots-by-resampling",
    "title": "Climate Coding Challenge",
    "section": "Clean up time series plots by resampling",
    "text": "Clean up time series plots by resampling\nYou may notice that your plot looks a little “fuzzy”. This happens when Python is trying to plot a value for every date, but the resolution of the image is too low to actually do that. You can address this issue by resampling the data, or summarizing it over a time period of your choice. In this case, we will resample annually, giving us one data point per year.\n\n\n\n\n\n\nTry It: Resample\n\n\n\n\nSet the frequency of your final data by replacing DT_OFFSETwith a Datetime Offset Code. Check out the table in the pandas datetime documentation to find the one you want (we recommend the start of the year).\nChoose how to summarize each year of data by replacing agg_method_here with a method that will calculate the average annual value. Check out the pandas resampling documentation for a list of common built-in options.\n\n\n\n\nann_climate_df = climate_df.resample('DT_OFFSET').agg_method_here()\nann_climate_df\n\n\n\nSee our solution!\nann_climate_df = climate_df.resample('YS').mean()\n# Store for later\n%store ann_climate_df\nann_climate_df\n\n\nStored 'ann_climate_df' (DataFrame)\n\n\n\n\n\n\n\n\n\nPRCP\nTOBS\n\n\nDATE\n\n\n\n\n\n\n1893-01-01\n0.025543\nNaN\n\n\n1894-01-01\n0.058841\nNaN\n\n\n1895-01-01\n0.117090\nNaN\n\n\n1896-01-01\nNaN\nNaN\n\n\n1897-01-01\n0.068922\nNaN\n\n\n...\n...\n...\n\n\n2019-01-01\n0.057644\n54.426997\n\n\n2020-01-01\n0.046721\n57.691460\n\n\n2021-01-01\n0.056658\n57.538462\n\n\n2022-01-01\n0.051479\n56.139726\n\n\n2023-01-01\n0.076740\n58.996337\n\n\n\n\n131 rows × 2 columns\n\n\n\n\n\n\n\n\n\nTry It: Plot Annual Data\n\n\n\n\nTry plotting your new DataFrame in the cell below. Can you see what is going on more clearly now? Don’t forget to adjust your labels!\n\n\n\n\n# Plot the annual data\n\n\n\nSee our solution!\n# Plot the annual data using .plot\nann_climate_df.plot(\n    y='TOBS',\n    title='Annual Average Temperature in Boulder, CO',\n    xlabel='Year',\n    ylabel='Temperature ($^\\circ$F)'\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflect and Respond: Interpret your plot\n\n\n\n\nCreate a new Markdown cell below this one.\nIn the new cell, answer the following questions using a bulleted list in Markdown – what are 2 things you notice about this data? What physical phenomena or data anomaly could be causing each one?",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#check-specific-values-with-an-interactive-plot",
    "href": "notebooks/01-climate/climate.html#check-specific-values-with-an-interactive-plot",
    "title": "Climate Coding Challenge",
    "section": "Check specific values with an interactive plot",
    "text": "Check specific values with an interactive plot\nYou can use the .hvplot() method with similar arguments to create an interactive plot.\n\n\n\n\n\n\nTry It: Interactive Plot\n\n\n\n\nCopy your plotting code into the cell below.\nReplace .plot in your code with .hvplot\n\nNow, you should be able to hover over data points and see their values!\n\n\n\n# Plot the annual data interactively\n\n\n\nSee our solution!\n# Plot the annual data using .plot\nann_climate_plot = ann_climate_df.hvplot(\n    y='TOBS',\n    title='Annual Average Temperature in Boulder, CO',\n    xlabel='Year',\n    ylabel='Temperature ($^\\circ$F)'\n)\nann_climate_plot\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\nTry It: Explore the data\n\n\n\n\nCreate a new Markdown cell below this one.\nHover over the lowest point on your plot. What is the overall minimum annual average temperature?",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "notebooks/01-climate/climate.html#bonus-save-your-work",
    "href": "notebooks/01-climate/climate.html#bonus-save-your-work",
    "title": "Climate Coding Challenge",
    "section": "BONUS: Save your work",
    "text": "BONUS: Save your work\nYou will need to save your analyses and plots to tell others about what you find.\n\n\n\n\n\n\nTry It: Save Your Plot\n\n\n\nJust like with any other type of object in Python, if you want to reuse your work, you need to give it a name.\n\nGo back to your hvplot code, and give your plot a name by assigning it to a variable. HINT: if you still want your plot to display in your notebook, make sure to call its name at the end of the cell.\nReplace my_plot with the name you gave to your plot.\nReplace 'my_plot.html' with the name you want for your plot. If you change the file extension, .html, to .png, you will get an image instead of an interactive webpage, provided you have the necessary libraries installed.\n\nOnce you run the code, you should see your saved plot in your files – go ahead and open it up.\n\n\n\n\n\n\nWarning\n\n\n\nYou may need to right-click on your file and download it to be able to view it.\n\n\n\n\n\nhv.save(my_plot, 'my_plot.html')\n\n\n\nSee our solution!\nhv.save(ann_climate_plot, 'annual_climate.html')\n\n\n\nformat: html\n\n\n\n\n\n\n\nTry It: Your Turn!\n\n\n\nWhat question do you want to answer with climate data? The options are limitless! To get started, you could think about:\n\nHow is climate change happening in your home town?\nHow is climate change different at different latitudes?\nDo heat waves affect urban areas more?",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Climate Coding Challenge",
      "Climate Coding Challenge"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html",
    "title": "What Is Open Reproducible Science",
    "section": "",
    "text": "In this chapter, you will learn about open reproducible science and become familiar with a suite of open source tools that are often used in open reproducible science (and earth data science) workflows including Shell, git and GitHub, Python, and Jupyter.\n\n\n\nAfter completing this chapter, you will be able to:\n\nDefine open reproducible science and explain its importance.\nDescribe how reproducibility can benefit yourself and others.\nList tools that can help you implement open reproducible science workflows.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "What Is Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#chapter-one---open-reproducible-science",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#chapter-one---open-reproducible-science",
    "title": "What Is Open Reproducible Science",
    "section": "",
    "text": "In this chapter, you will learn about open reproducible science and become familiar with a suite of open source tools that are often used in open reproducible science (and earth data science) workflows including Shell, git and GitHub, Python, and Jupyter.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "What Is Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#learning-objectives",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#learning-objectives",
    "title": "What Is Open Reproducible Science",
    "section": "",
    "text": "After completing this chapter, you will be able to:\n\nDefine open reproducible science and explain its importance.\nDescribe how reproducibility can benefit yourself and others.\nList tools that can help you implement open reproducible science workflows.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "What Is Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#what-is-open-reproducible-science",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#what-is-open-reproducible-science",
    "title": "What Is Open Reproducible Science",
    "section": "What is Open Reproducible Science",
    "text": "What is Open Reproducible Science\nOpen science involves making scientific methods, data, and outcomes available to everyone. It can be broken down into several parts (Gezelter 2009) including:\n\nTransparency in data collection, processing and analysis methods, and derivation of outcomes.\nPublicly available data and associated processing methods.\nTransparent communication of results.\n\nOpen science is also often supported by collaboration.\nReproducible science is when anyone (including others and your future self) can understand and replicate the steps of an analysis, applied to the same or even new data.\nTogether, open reproducible science results from open science workflows that allow you to easily share work and collaborate with others as well as openly publish your data and workflows to contribute to greater science knowledge.\n\n \n\nAn open science workflow highlighting the roles of data, code, and workflows. Source: Max Joseph, Earth Lab at University of Colorado, Boulder.\n\n\nClick through the slideshow below to learn more about open science.\n  View Slideshow: Share, Publish & Archive Code & Data\n\n\n\nWatch this 15 minute video to learn more about the importance of reproducibility in science and the current reproducibility “crisis.”",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "What Is Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#benefits-of-open-reproducible-science",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#benefits-of-open-reproducible-science",
    "title": "What Is Open Reproducible Science",
    "section": "Benefits of Open Reproducible Science",
    "text": "Benefits of Open Reproducible Science\nBenefits of openness and reproducibility in science include: * Transparency in the scientific process, as anyone including the general public can access the data, methods, and results. * Ease of replication and extension of your work by others, which further supports peer review and collaborative learning in the scientific community. * It supports you! You can easily understand and re-run your own analyses as often as needed and after time has passed.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "What Is Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#how-do-you-make-your-work-more-open-and-reproducible",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#how-do-you-make-your-work-more-open-and-reproducible",
    "title": "What Is Open Reproducible Science",
    "section": "How Do You Make Your Work More Open and Reproducible?",
    "text": "How Do You Make Your Work More Open and Reproducible?\nThe list below are things that you can begin to do to make your work more open and reproducible. It can be overwhelming to think about doing everything at once. However, each item is something that you could work towards.\n\nUse Scientific Programming to Process Data\nScientific programming allows you to automate tasks, which facilitates your workflows to be quickly run and replicated. In contrast, graphical user interface (GUI) based workflows require interactive manual steps for processing, which become more difficult and time consuming to reproduce. If you use an open source programming language like Python or R, then anyone has access to your methods. However, if you use a tool that requires a license, then people without the resources to purchase that tool are excluded from fully reproducing your workflow.\n\n\nUse Expressive Names for Files and Directories to Organize Your Work\nExpressive file and directory names allow you to quickly find what you need and also support reproducibility by facilitating others’ understanding of your files and workflows (e.g. names can tell others what the file or directory contains and its purpose). Be sure to organize related files into directories (i.e. folders) that can help you easily categorize and find what you need (e.g. raw-data, scripts, results).\n\n\nUse FAIR Data to Enhance the Reproducibility of Projects\nMake sure that the data used in your project adhere to the FAIR principles (Wilkinson et al. 2016), so that they are findable, accessible, interoperable, and re-usable, and there is documentation on how to access them and what they contain. FAIR principles also extend beyond the raw data to apply to the tools and workflows that are used to process and create new data. FAIR principles enhance the reproducibility of projects by supporting the reuse and expansion of your data and workflows, which contributes to greater discovery within the scientific community.\n\n\nProtect Your Raw Data\nDon’t modify (or overwrite) the raw data. Keep data outputs separate from inputs, so that you can easily re-run your workflow as needed. This is easily done if you organize your data into directories that separate the raw data from your results, etc.\n\n\nUse Version Control and Share Your Code (If You Can)\nVersion control allows you to manage and track changes to your files (and even undo them!). If you can openly share your code, implement version control and then publish your code and workflows on the cloud. There are many free tools to do this including Git and GitHub.\n\n\nDocument Your Workflows\nDocumentation can mean many different things. It can be as basic as including (carefully crafted and to the point) comments throughout your code to explain the specific steps of your workflow. Documentation can also mean using tools such as Jupyter Notebooks or RMarkdown files to include a text narrative in Markdown format that is interspersed with code to provide high level explanation of a workflow.\nDocumentation can also include docstrings, which provide standardized documentation of Python functions, or even README files that describe the bigger picture of your workflow, directory structure, data, processing, and outputs.\n\n\nDesign Workflows That Can Be Easily Recreated\nYou can design workflows that can be easily recreated and reproduced by others by: * listing all packages and dependencies required to run a workflow at the top of the code file (e.g. Jupyter Notebook or R Markdown files). * organizing your code into sections, or code blocks, of related code and include comments to explain the code. * creating reusuable environments for Python workflows using tools like docker containers, conda environments, and interactive notebooks with binder.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "What Is Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#open-reproducible-science---a-case-study",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/01-intro.html#open-reproducible-science---a-case-study",
    "title": "What Is Open Reproducible Science",
    "section": "Open Reproducible Science - A Case Study",
    "text": "Open Reproducible Science - A Case Study\nChaya is a scientist at Generic University, studying the role of invasive grasses on fires in grassland areas. She is building models of fire spread as they relate to vegetation cover. This model uses data collected from satellites that detect wildfires and also plant cover maps. After documenting that an invasive plant drastically alters fire spread rates, she is eager to share her findings with the world. Chaya uses scientific programming rather than a graphical user interface tool such as Excel to process her data and run the model to ensure that the process is automated. Chaya writes a manuscript on her findings. When she is ready to submit her article to a journal, she first posts a preprint of the article on a preprint server, stores relevant data in a data repository and releases her code on GitHub. This way, the research community can provide feedback on her work, the reviewers and others can reproduce her analysis, and she has established precedent for her findings.\nIn the first review of her paper, which is returned 3 months later, many changes are suggested which impact her final figures. Updating figures could be a tedious process. However, in this case, Chaya has developed these figures using the Python programming language. Thus, updating figures is easily done by modifying the processing methods used to create them. Further because she stored her data and code in a public repository on GitHub, it is easy and quick for Chaya three months later to find the original data and code that she used and to update the workflow as needed to produce the revised versions of her figures. Throughout the review process, the code (and perhaps data) are updated, and new versions of the code are tracked. Upon acceptance of the manuscript, the preprint can be updated, along with the code and data to ensure that the most recent version of the paper and analysis are openly available for anyone to use.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "What Is Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html",
    "title": "Tools For Open Reproducible Science",
    "section": "",
    "text": "{% include toc title=“On This Page” icon=“file-text” %}",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "Tools For Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#learning-objectives",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#learning-objectives",
    "title": "Tools For Open Reproducible Science",
    "section": " Learning Objectives",
    "text": "Learning Objectives\n\nDescribe how bash, git, GitHub and Jupyter can help you implement open reproducible science workflows.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "Tools For Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#useful-tools-in-the-open-reproducible-science-toolbox",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#useful-tools-in-the-open-reproducible-science-toolbox",
    "title": "Tools For Open Reproducible Science",
    "section": "Useful Tools in the Open Reproducible Science Toolbox",
    "text": "Useful Tools in the Open Reproducible Science Toolbox\nTo implement open science workflows, you need tools that help you document, automate, and share your work. For example you may need to document how you collected your data (protocols), how the data were processed and what analysis approaches you used to summarize the data.\nThroughout this textbook, you will learn how to use open science tools that will help you: * Document your work, so others and your future self can understand your workflow. * Generate reports that connect your data, code (i.e. methods used to process the data), and outputs and publish them in different formats (HTML, PDF, etc). * Automate your workflows, so they can be reproduced by others and your future self. * Share your workflows. * Collaborate with others.\nWhile there are many tools that support open reproducible science, this textbook uses: bash, git,GitHub.com, and Python in Jupyter Notebooks.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "Tools For Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#use-scientific-programming-to-automate-workflows",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#use-scientific-programming-to-automate-workflows",
    "title": "Tools For Open Reproducible Science",
    "section": "Use Scientific Programming to Automate Workflows",
    "text": "Use Scientific Programming to Automate Workflows\nMany people begin to use data in tools such as Microsoft Excel (for spreadsheets / tabular data) or ArcGIS (for spatial data) that have graphical user interfaces (GUIs). GUIs can be easier to learn early on as they have a visual interface that can be less overwhelming as a beginner. However, as the data that you are working with get larger, you will often run into challenges where the GUI based tools can not handle larger volumes of data. Further GUI based tools require individual steps that are often manually implemented (unless you build macros or small automation scripts). This makes your workflow difficult to reproduce. Some tools such as Excel require paid licenses which will limit who can access your data and further, will limit including your workflow in a cloud or other remote environment.\nScientific programming using an open source, free programming language like R or Python, is an effective and efficient way to begin building a workflow that is both reproducible and that can be easily shared.\nIn this textbook, you will learn the Python programming language. Python is a free and open source programming language that anyone can download and use. Further it is becomming one of the more popular and in-demand skills in today’s job market. While you will learn Python in this textbook, many of the principles that you will learn can be applied across many programming languages.\n\n \n\nYou can write and run Python code in interactive development environments such as Jupyter Notebook. This image shows how Python code can be organized and run using cells in Jupyter Notebook and how the output is displayed under the executed cells.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "Tools For Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#use-shell-also-called-bash-for-file-manipulation-and-management",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#use-shell-also-called-bash-for-file-manipulation-and-management",
    "title": "Tools For Open Reproducible Science",
    "section": "Use Shell (Also Called Bash) For File Manipulation and Management",
    "text": "Use Shell (Also Called Bash) For File Manipulation and Management\nShell is the primary program that computers use to receive code (i.e. commands) and return information produced by executing these commands (i.e. output). These commands can be entered via a Terminal (also known as a Command Line Interface - CLI), which you will work with in this course.\nUsing a Shell helps you: * Navigate your computer to access and manage files and folders (i.e. directories). * Efficiently work with many files and directories at once. * Run programs that provide more functionality at the command line such as git for version control. * Launch programs from specific directories on your computer such as Jupyter Notebook for interactive programming. * Use repeatable commands for these tasks across many different operating systems (Windows, Mac, Linux).\nShell is also important if you need to work on remote machines such as a high performance computing cluster (HPC) or the cloud. Later in this textbook, you will learn how to use a Bash (a specific implementation of Shell) to access and manage files on your computer and to run other programs that can be started or run from the Terminal, such as Jupyter Notebook and git.\n\n \n\nThe terminal and shell (bash) can be used to view file directory structures. The image above shows bash commands to change directories (cd) from the home directory to a subdirectory called earth-analytics, and to list out the contents (ls) of the earth-analytics directory, which includes a subdirectory called data.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "Tools For Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#version-control-and-collaboration-using-git-and-github",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#version-control-and-collaboration-using-git-and-github",
    "title": "Tools For Open Reproducible Science",
    "section": "Version Control and Collaboration Using Git and GitHub",
    "text": "Version Control and Collaboration Using Git and GitHub\nGit helps you monitor and track changes in files, a process referred to as version control. Git provides a way to create and track a “repository” for a project, i.e., a folder where all relevant files are kept. GitHub is a cloud-based platform to host git repositories, which allows you to store and manage your files and track changes. GitHub also includes project management and communication features that are useful when working on collaborative projects such as issues, forks, and milestone tracking.\nThese tools work together to support sharing files and collaboration within workflows. With git, you can work on your files locally and then upload changes to GitHub.com. If you make your repository public, then others can find it on GitHub and contribute to your code (if you want them to) which makes it ideal for collaboration and sharing. GitHub is also useful for code review as others can comment on changes to a workflow and you can chose to accept or reject proposed changes.\nLater in this textbook, you will learn how to use the git/GitHub workflow to implement version control for your files, share work and collaborate with others.\n\n \n\nYou can make local copies on your computer of repositories on Github.com, using git commands that you run in the Terminal. It’s valuable to have copies of your code in multiple places (for example, on your computer and GitHub) just in case something happens to your computer.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "Tools For Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#the-jupyter-project",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/02-open-science-tools.html#the-jupyter-project",
    "title": "Tools For Open Reproducible Science",
    "section": "The Jupyter Project",
    "text": "The Jupyter Project\nThe Jupyter project is an open source effort that evolved from the IPython project to support interactive data science and computing. While the project evolved from Python, it supports many different programming languages including R, Python and Julia and was designed to be language-agnostic. The Jupyter platform has been widely adopted by the public and private sector science community. If you are familiar with the R programming language, Jupyter Notebook can be compared to R Markdown.\nThere are three core tools that you should be familiar with associated with Project Jupyter. The text below which describes these tools was copied directly from the  Jupyter Website:\nJupyter Notebook: The Jupyter Notebook is an open-source browser-based application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\n\n \n\nA Jupyter Notebook file can contain both text documentation as well as programming code, which can be executed interactively within Jupyter Notebook.\n\n\nJupyterLab: JupyterLab is a browser-based interactive development environment for Jupyter notebooks, code, and data. JupyterLab is flexible: you can configure and arrange the user interface to support a wide range of workflows in data science, scientific computing, and machine learning. JupyterLab is extensible and modular: you can write plugins that add new components and integrate with existing ones.\n\n \n\nJupyter Notebook (left) is a browser-based interface that allows you to write code in many programming languages, including Python, and add formatted text that describes what the code does using Markdown. Jupyter Lab (right) provides access to Jupyter Notebook but also allows you to work with multiple documents, including notebook files and other files, at a time.\n\n\nJupyterHub: A multi-person version of Jupyter Notebook and Lab that can be run on a server. This is the tool that supports the cloud based classroom used in all of the Earth Analytics courses and workshops.\nYou will learn more about Jupyter tools in later chapters of this book.\n\nOrganize and Document Workflows Using Jupyter Notebook Files\nConnecting your entire workflow including accessing the data, processing methods and outputs is an important part of open reproducible science.\nJupyter Notebook files can help you connect your workflow by allowing you to write and run code interactively as well as organize your code with documentation and results within individual Jupyter Notebook files. You can also export Jupyter Notebook files to HTML and PDF formats for easy sharing.\nIn this textbook and in our Earth Analytics courses, we use Jupyter Notebook with Python. As described previously, Python is a widely used programming language in the sciences and provides strong functionality for working with a variety of data types and formats.\nWriting and organizing your Python code within Jupyter Notebook files supports open reproducible science through documentation of data inputs, code for analysis and visualization, and results – all within one file that can be easily shared with others.\nIn later chapters, you will learn how to use Jupyter Notebook to write and run Python code for analysis and visualization of earth and environmental science data.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "Tools For Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/03-best-practices.html",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/03-best-practices.html",
    "title": "How To Organize Your Project: Best Practices for Open Reproducible Science",
    "section": "",
    "text": "When you are working on a data project, there are often many files that you need to store on your computer. These files may include:\n\nRaw Data Files\nProcessed data files: you may need to take the raw data and process it in some way\nCode and scripts\nOutputs like figures and tables\nWriting associated with your project\n\nIt will save you time and make your project more useable and reproducible if you carefully consider how these files are stored on your computer. Below are some best practices to consider when pulling together a project.\n\n\n\nAs you create new directories and files on your computer, consider using a carefully crafted naming convention that makes it easier for anyone to find things and also to understand what each files does or contains.\nIt is good practice to use file and directory that are:\n\nHuman readable: use expressive names that clearly describe what the directory or file contains (e.g. code, data, outputs, figures).\nMachine readable: avoid strange characters or spaces. Instead of spaces, you can use - or _ to separate words within the name to make them easy to read and parse.\nSortable: it is nice to be able to sort files to quickly see what is there and find what you need. For example, you can create a naming convention for a list of related directories or files (e.g. 01-max.jpg, 02-terry.jpg, etc), which will result in sortable files.\n\nThese guidelines not only help you to organize your directories and files, but they can also help you to implement machine readable names that can be easily queried or parsed using scientific programming or other forms of scripting.\nUsing a good naming convention when structuring a project directory also supports reproducibility by helping others who are not familiar with your project quickly understand your directory and file structure.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "How To Organize Your Project: Best Practices for Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/03-best-practices.html#project-organization-and-management-for-open-reproducible-science-projects",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/03-best-practices.html#project-organization-and-management-for-open-reproducible-science-projects",
    "title": "How To Organize Your Project: Best Practices for Open Reproducible Science",
    "section": "",
    "text": "When you are working on a data project, there are often many files that you need to store on your computer. These files may include:\n\nRaw Data Files\nProcessed data files: you may need to take the raw data and process it in some way\nCode and scripts\nOutputs like figures and tables\nWriting associated with your project\n\nIt will save you time and make your project more useable and reproducible if you carefully consider how these files are stored on your computer. Below are some best practices to consider when pulling together a project.\n\n\n\nAs you create new directories and files on your computer, consider using a carefully crafted naming convention that makes it easier for anyone to find things and also to understand what each files does or contains.\nIt is good practice to use file and directory that are:\n\nHuman readable: use expressive names that clearly describe what the directory or file contains (e.g. code, data, outputs, figures).\nMachine readable: avoid strange characters or spaces. Instead of spaces, you can use - or _ to separate words within the name to make them easy to read and parse.\nSortable: it is nice to be able to sort files to quickly see what is there and find what you need. For example, you can create a naming convention for a list of related directories or files (e.g. 01-max.jpg, 02-terry.jpg, etc), which will result in sortable files.\n\nThese guidelines not only help you to organize your directories and files, but they can also help you to implement machine readable names that can be easily queried or parsed using scientific programming or other forms of scripting.\nUsing a good naming convention when structuring a project directory also supports reproducibility by helping others who are not familiar with your project quickly understand your directory and file structure.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "How To Organize Your Project: Best Practices for Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/03-best-practices.html#best-practices-for-open-reproducible-science-projects",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/03-best-practices.html#best-practices-for-open-reproducible-science-projects",
    "title": "How To Organize Your Project: Best Practices for Open Reproducible Science",
    "section": "Best Practices for Open Reproducible Science Projects",
    "text": "Best Practices for Open Reproducible Science Projects\n\n1. Use Consistent Computer Readable Naming Conventions\nMachine readable file names allow your directory structure to be quickly manipulated and handled by code.\nFor example, you may want to write a script that processes a set of images and you may want to sort those images by date. If the date of each image is included in the file name at the very beginning of the name, it will become easier to parse with your code. The files below could be difficult to parse because the naming convention is not standard.\n```{bash}\n* file.jpg\n* file-two.jpg\n* filethree.jpg\n```\nHowever this list of files is easier to parse as the date is included with the file name.\n```{bash}\n* 2020-image.jpg\n* 2019-image.jpg\n* 2018-image.jpg\n```\nSometimes simply numbering the files is enough to allow for sorting:\n```{bash}\n* 01-image.jpg\n* 02-image.jpg\n* 03-image.jpg\n```\nIf your files and directories follow identifiable patterns or rules, it will allow you to more easily manipulate them. This in turn will make it easier for you to automate file processing tasks.\nA few other best practices to consider when naming files within a project:\n\nAvoid spaces in file and dir names: spaces in a file name can be difficult when automating workflows.\nUse dashes-to-separate-words (slugs): dashes or underscores can make is easier for you to create expressive file names. Dashes or underscores are also easier to parse when coding.\nConsider whether you may need to sort your files. If you do, you may want to number things.\n\n\n\n2. Be Consistent When Naming Files - Use Lower Case\nIt might be tempting when naming files and directories to use lower and Upper case. However, case will cause coding issues for you down the road particularly if you are switching between operating systems (Mac vs Linux vs Windows).\nCase in point, have a look at the file names below.\n```{bash}\nmy-file.txt\nMy-File.txt\n```\nIf you want to open / read my-file.txt it would be easy to call:\npandas.read.csv(\"my-file.txt\")\nin Python. This call will work on all operating systems. However, this call:\npandas.read.csv(\"My-file.txt\")\nmay work on some machines (possibly Windows) but it’s likely to fail on Linux or MAC. To keep things simple and to avoid case sensitvity issues, use lower case naming conventions for all file and directory names.\n\n\n3. Organize Your Project Directories to Make It Easy to Find Data, Code and Outputs\nRather than saving a bunch of files into a single directory, consider a directory organization approach that fits your project.\nCreate numbered directories that cover the steps of your workflow - for example:\n```{bash}\n/vegetation-health-project\n    /01-code-scripts\n    /02-raw-data\n    /03-processed-data\n    /04-graphics-outputs\n    /05-paper-blog\n```\nThe numbers before each folder allow you to sort the directories in a way that makes it easier to parse. Notice also that each directory has an expressive (uses words that describe what is in the directory) name. Expressive naming will be discussed in the next section.\nUsing individual directories to store data, scripts, output graphics and then the final paper and blog posts being written for the project makes it easier to find components of your project.\nThis is especially useful for your future self who may need to come back to the project in six months to update things. It also makes is easier for a colleague that you are collaborating with to quickly find things.\nThere is no one perfect example as each project may require different directories. The best advice is to pick something that works well for you and your team and stick to it. It’s best to be consistent.\n\n\n\n\n\n\n\n\nOrganized Project\nNon Organized Project\n\n\n\n\n/01-scripts     01-clean-data.py      02-run-model.py     03-create-plots.py  /02-data      /raw-data          /landsat-imagery         /fire-boundary/03-output-graphics    study-area-map.png  /04-final-paper     fire-paper.pdf\nfile1-new.pyfile1.py plotting-test.py  data-file.txt  /old-stuff  testoutput1.txt testoutput2.csv\n\n\n\n\nLook at the example directory structures above. Which structure is easier to understand? In which could you more easily find what you need?\n\n\n\n\n4. Use Meaningful (Expressive) File And Directory Names\nExpressive file names are those that are meaningful and thus describe what each directory or file is or contains. Using expressive file names makes it easier to scan a project directory and quickly understand where things are stored and what files do or contain.\nExpressive names also support machine readibility, as discernible patterns in expressive names can be used by a computer to identify and parse files.\n\n\n\n\n\n\n\n\nExpressive Project\nNon Expressive Project\n\n\n\n\n/01-scripts     01-process-landsat-data.py      02-calculate-ndvi.py     03-create-ndvi-maps.py  /02-data      /raw-data          /landsat-imagery                /june-2016                /july-2016         /cold-springs-fire-boundary/03-output-graphics    ndvi-map-june-2016.png      ndvi-map-july-2016.png /04-final-paper     veg-impacts-cold-springs-fire.pdf\nwork.pyplotting.py plotting-test.py landsat/ data-file.txt old-stuff/  testoutput1.txt testoutput2.csv\n\n\n\n\nLook at the example directory structures above. Which directory structure (the one on the LEFT or the one on the RIGHT) would you prefer to work with?\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWindows Users: Note that the default names of your existing directories often begin with upper case letters (e.g. Documents, Downloads). When creating new directories, use lower case to follow the textbook more easily and for best results from future programming tasks.\n\n\n\n\n5. Document Your Project With a README File\nThere are many ways to document a project; however, a readme file at the top level of your project is a standard convention. When you begin to use GitHub, you will notice that almost all well designed github repositories contain readme files. The readme is a text file that describes data / software packages and tools used to process data in your project. The readme should also describe files and associated naming conventions. Finally, the readme can be used to document any abbreviations used, units, etc as needed.\nThere are other files that you may consider as well such as software installation instructions if those are required, citation information and if the project is one that you want others to contribute to, then a CONTRIBUTING file may be in order.\n\n\n6. Don’t Use Proprietary File Formats\nProprietary formats are formats that require a specific tool (and a specific license often) to open. Examples include Excel (.xls) or Word (.doc). These formats may change over time as new versions come out (example: .xls upgraded to .xlsx.\nIn some cases, certain formats are operating system specific (example: most Linux users do not run Microsoft tools).\nWhen choosing file formats for your projects, think about whether you will have a license to access that file format in the future and whether others have access to the license.\nWhen you can, stick to formats that are operating system and tool agnostic such as .csv and .txt. Text files are not proprietary and thus can be opened on any operating system and on any computer with the right open tools. This allows more people to have access to your files including your future self who might not have a license to open these files.\n\n\n\n\n\n\nTip\n\n\n\nUsing standard data formats increases opportunities for re-use and expansion of your research.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "How To Organize Your Project: Best Practices for Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/01-reproducible-science-tools/open-reproducible-science/03-best-practices.html#best-practices-for-open-reproducible-science-projects---a-case-study",
    "href": "pages/01-reproducible-science-tools/open-reproducible-science/03-best-practices.html#best-practices-for-open-reproducible-science-projects---a-case-study",
    "title": "How To Organize Your Project: Best Practices for Open Reproducible Science",
    "section": "Best Practices For Open Reproducible Science Projects - A Case Study",
    "text": "Best Practices For Open Reproducible Science Projects - A Case Study\nJennifer recently graduated with a degree in environmental science and got a job working with an environmental non-profit. While a student, she worked on some great projects to build flood models using MATLAB, a proprietary software used to design and run models. In collaboration with a professor and other class mates, Jennifer wrote a paper that was accepted for publication in well known hydrology journal, though some minor changes were requested.\nExcited to get the paper revised for publication, Jennifer tracks down her project files and tries to remember which files produced the final outputs that she included in the submitted paper. However, she realizes that even when she is able to identify which files she needs, she no longer has access to the MATLAB, which she needs to access the files. Unfortunately, her license expired when she graduated, and her non-profit does not have licenses for MATLAB.\nJennifer’s story can be a common experience for anyone who has moved to a new job where the resources and licenses differ, or who has spent a long time away from a particular project and need to recreate a workflow.\nHow could using organized and expressively named directories have helped Jennifer with this project? How could avoiding proprietary file formats contribute to the longevity of this project?",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 2: Climate Change",
      "Open Science Tools",
      "How To Organize Your Project: Best Practices for Open Reproducible Science"
    ]
  },
  {
    "objectID": "pages/00-course-overviews/stars/00-home.html",
    "href": "pages/00-course-overviews/stars/00-home.html",
    "title": "ESIIL Stars",
    "section": "",
    "text": "We are excited to have you in class as we introduce you to Earth and Environmental Data Science (EDS) fundamentals using Python.\nESIIL Stars is modeled after the Harnessing the Data Revolution (HDR) Earth Data Science Corps (EDSC), which took place from 2020-2022. Both of these programs are funded by the National Science Foundation (NSF).\nESIIL Stars aims to meet the following objectives through technical training and project based learning:\n\nTrain the next generation of Earth and Environmental Data Scientists\nAnswer relevant GIS and Earth/Environmental science questions\nDiversify the EDS workforce\nBuild capacity to teach & learn EDS at partner institutions\n\nThis work represents a partnership between Oglala Lakota College (OLC), Metropolitan State University of Denver (MSU), United Tribes Technical College (UTTC), and The Environmental Data Science Innovation and Inclusion Lab (ESIIL). ESIIL is a part of the Cooperative Institute for Research in Environmental Sciences (CIRES) a partnership of the University of Colorado Boulder and the National Oceanic and Atmospheric Administration (NOAA). We are also affiliated with Earth Lab.\nWe appreciate these partnerships and look forward to working with you all!"
  },
  {
    "objectID": "pages/00-course-overviews/stars/00-home.html#welcome-to-the-esiil-stars-internship",
    "href": "pages/00-course-overviews/stars/00-home.html#welcome-to-the-esiil-stars-internship",
    "title": "ESIIL Stars",
    "section": "",
    "text": "We are excited to have you in class as we introduce you to Earth and Environmental Data Science (EDS) fundamentals using Python.\nESIIL Stars is modeled after the Harnessing the Data Revolution (HDR) Earth Data Science Corps (EDSC), which took place from 2020-2022. Both of these programs are funded by the National Science Foundation (NSF).\nESIIL Stars aims to meet the following objectives through technical training and project based learning:\n\nTrain the next generation of Earth and Environmental Data Scientists\nAnswer relevant GIS and Earth/Environmental science questions\nDiversify the EDS workforce\nBuild capacity to teach & learn EDS at partner institutions\n\nThis work represents a partnership between Oglala Lakota College (OLC), Metropolitan State University of Denver (MSU), United Tribes Technical College (UTTC), and The Environmental Data Science Innovation and Inclusion Lab (ESIIL). ESIIL is a part of the Cooperative Institute for Research in Environmental Sciences (CIRES) a partnership of the University of Colorado Boulder and the National Oceanic and Atmospheric Administration (NOAA). We are also affiliated with Earth Lab.\nWe appreciate these partnerships and look forward to working with you all!"
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/05-map.html",
    "href": "pages/03-git-github/03-github-portfolio/05-map.html",
    "title": "Add a map to your website",
    "section": "",
    "text": "Check out our video demo for adding a map to your portfolio:\n\n \n\nDEMO: Add a map to your portfolio by ESIIL\n\n\n\n\n\nVector data are composed of discrete geometric locations (x and y values, or latitude and longitude) that define the “shape” of the spatial object. The organization of the vertices determines the type of vector that you are working with. There are three fundamental types of vector data:\nPoints: Each individual point is defined by a single x, y coordinate. Examples of point data include: sampling locations, the location of individual trees or the location of plots.\nLines: Lines are composed of many (at least 2) vertices, or points, that are connected. For instance, a road or a stream may be represented by a line. This line is composed of a series of segments, each bend in the road or stream represents a vertex that has defined x, y location.\nPolygons: A polygon consists of 3 or more vertices that are connected and closed. Thus, the outlines of plot boundaries, lakes, oceans, and states or countries are often represented by polygons.\n\n\n\nThere are three types of vector data – point, line, and polygon\n\n\n\n\n\n\n\n\nTip\n\n\n\nRead more about working with spatial data using Python in our Intro to Earth Data Science, here.\n\n\n\n\n\nTo complete this activity, you will need somewhere to run your code. Start by going to this repository on GitHub. We’ve set it up so that anyone can run Python code from there!\nOnce you are on the website, follow these instructions to get your Codespace up and running:\n\nClick on Use this Template in the upper right, and select Open in Codespace. This might take a minute if you haven’t done it in awhile.\nOnce the Codespace loads, open !00-first-map.ipynb using the Folders tab on the left-hand side.\nContinue working through the sample notebook. All the code should start off the same as what is on this page, but there’s more background information here if you want it.\nOnce you are done, stop your Codespace so you don’t use up your allocation!\n\n\n\n\nOpen Street Map (OSM) is an open-source, editable map of the world – a little like a wiki for places. They also provide a service for looking up locations using text, which we’ll be using in this activity.\n\n\n\nYou’ll need to start by importing some libraries to have access to all the code you need.\n\n# Work with vector data\nimport geopandas as gpd\n\n# Save maps and plots to files\nimport holoviews as hv\n# Create interactive maps and plots\nimport hvplot.pandas\n\n# Search for locations by name - this might take a moment\nfrom osmnx import features as osm\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\nYou can use the osmnx package to download and search for spatial vector data in your area, or anywhere around the world.\nIn this case, we’re looking for the location of the United Tribes Technical College campus in North Dakota. The address in here, 'United Tribes Technical College, Bismarck, ND, United States', does not have to be complete or exact, but it should be specific enough to narrow it down.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the Open Street Maps website to fine-tune your address before you copy it into your code.\n\n\nWe are also specifying that we want it to be tagged as a 'college' type of‘amenity’` type. You might have to try a couple different searches with different addresses and/or tags to get the address you want, just like if you are using a map website or app.\n\n\n\n\n\n\nTip\n\n\n\nCheck out the list of all the different amenity types available on Open Street Maps! Different amenity types might be different types of vector data, such as a point location or a building footprint polygon.\n\n\n\n# Search for United Tribes Technical College\nuttc_gdf = osm.features_from_address(\n    'United Tribes Technical College, Bismarck, ND, United States',\n    {'amenity': ['college']})\nuttc_gdf\n\n\n\n\n\n\n\n\n\nnodes\naddr:city\naddr:housenumber\naddr:postcode\naddr:state\naddr:street\namenity\nname\nwebsite\nwikidata\ngeometry\n\n\nelement_type\nosmid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nway\n1157021269\n[10759584855, 10759584856, 10759584857, 450404...\nBismarck\n3315\n58504\nND\nUniversity Drive\ncollege\nUnited Tribes Technical College\nhttps://uttc.edu/\nQ7893617\nPOLYGON ((-100.76305 46.76853, -100.76302 46.7...\n\n\n\n\n\n\n\n\nuttc_gdf.plot()\n\n/usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/IPython/core/pylabtools.py:77: DeprecationWarning: backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nWe have a map of the UTTC Campus!\n\n\n\n\n\n\nWarning\n\n\n\nThe Open Street Maps (OSM) database is not always complete. For example, try searching for UTTC with the {'building': True}, and compare it to the map of the UTTC campus on their website. What do you notice?\n\n\n\n\n\nThere are lots of different ways to create maps and plots in Python. Here, we’re going to use a tool called 'hvplot' and 'geoviews' to create an interactive map, including the online 'EsriImagery' tile source basemap.\n\n# Plot UTTC boundary\nuttc_map = uttc_gdf.hvplot(\n    # Givethe map a descriptive title\n    title=\"United Tribes Technical College, Bismarck, ND\",\n    # Add a basemap\n    geo=True, tiles='EsriImagery',\n    # Change the colors\n    fill_color='white', fill_alpha=0.2,\n    line_color='skyblue', line_width=5,\n    # Change the image size\n    frame_width=400, frame_height=400)\n\n# Save the map as a file to put on the web\nhv.save(uttc_map, 'uttc.html')\n\n# Display the map\nuttc_map\n\nWARNING:bokeh.core.validation.check:W-1005 (FIXED_SIZING_MODE): 'fixed' sizing mode requires width and height to be set: figure(id='p1053', ...)\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\nIf you are doing this activity on GitHub Codespaces, you will need to download the map you created:\n\nOpen the Folders tab on the left hand side\nRight-click on uttc.html (or whatever you named your file)\nSelect Download...\n\nThis should download your map.\n\n\n\nYou are now ready to upload your map to your portfolio repository and place it in your webpage. Because it is HTML and not an image, you will need to use the following HTML to get it on your page:\n&lt;embed type=\"text/html\" src=\"uttc.html\" width=\"600\" height=\"600\"&gt;\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure to make the width and height of your embed element larger than the frame_width and frame_height of your plot, or it will get cut off!\n\n\n:::",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 5: Add a map"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/05-map.html#get-started-with-map-making-using-open-sources-tools",
    "href": "pages/03-git-github/03-github-portfolio/05-map.html#get-started-with-map-making-using-open-sources-tools",
    "title": "Add a map to your website",
    "section": "",
    "text": "Check out our video demo for adding a map to your portfolio:\n\n \n\nDEMO: Add a map to your portfolio by ESIIL\n\n\n\n\n\nVector data are composed of discrete geometric locations (x and y values, or latitude and longitude) that define the “shape” of the spatial object. The organization of the vertices determines the type of vector that you are working with. There are three fundamental types of vector data:\nPoints: Each individual point is defined by a single x, y coordinate. Examples of point data include: sampling locations, the location of individual trees or the location of plots.\nLines: Lines are composed of many (at least 2) vertices, or points, that are connected. For instance, a road or a stream may be represented by a line. This line is composed of a series of segments, each bend in the road or stream represents a vertex that has defined x, y location.\nPolygons: A polygon consists of 3 or more vertices that are connected and closed. Thus, the outlines of plot boundaries, lakes, oceans, and states or countries are often represented by polygons.\n\n\n\nThere are three types of vector data – point, line, and polygon\n\n\n\n\n\n\n\n\nTip\n\n\n\nRead more about working with spatial data using Python in our Intro to Earth Data Science, here.\n\n\n\n\n\nTo complete this activity, you will need somewhere to run your code. Start by going to this repository on GitHub. We’ve set it up so that anyone can run Python code from there!\nOnce you are on the website, follow these instructions to get your Codespace up and running:\n\nClick on Use this Template in the upper right, and select Open in Codespace. This might take a minute if you haven’t done it in awhile.\nOnce the Codespace loads, open !00-first-map.ipynb using the Folders tab on the left-hand side.\nContinue working through the sample notebook. All the code should start off the same as what is on this page, but there’s more background information here if you want it.\nOnce you are done, stop your Codespace so you don’t use up your allocation!\n\n\n\n\nOpen Street Map (OSM) is an open-source, editable map of the world – a little like a wiki for places. They also provide a service for looking up locations using text, which we’ll be using in this activity.\n\n\n\nYou’ll need to start by importing some libraries to have access to all the code you need.\n\n# Work with vector data\nimport geopandas as gpd\n\n# Save maps and plots to files\nimport holoviews as hv\n# Create interactive maps and plots\nimport hvplot.pandas\n\n# Search for locations by name - this might take a moment\nfrom osmnx import features as osm\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\nYou can use the osmnx package to download and search for spatial vector data in your area, or anywhere around the world.\nIn this case, we’re looking for the location of the United Tribes Technical College campus in North Dakota. The address in here, 'United Tribes Technical College, Bismarck, ND, United States', does not have to be complete or exact, but it should be specific enough to narrow it down.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the Open Street Maps website to fine-tune your address before you copy it into your code.\n\n\nWe are also specifying that we want it to be tagged as a 'college' type of‘amenity’` type. You might have to try a couple different searches with different addresses and/or tags to get the address you want, just like if you are using a map website or app.\n\n\n\n\n\n\nTip\n\n\n\nCheck out the list of all the different amenity types available on Open Street Maps! Different amenity types might be different types of vector data, such as a point location or a building footprint polygon.\n\n\n\n# Search for United Tribes Technical College\nuttc_gdf = osm.features_from_address(\n    'United Tribes Technical College, Bismarck, ND, United States',\n    {'amenity': ['college']})\nuttc_gdf\n\n\n\n\n\n\n\n\n\nnodes\naddr:city\naddr:housenumber\naddr:postcode\naddr:state\naddr:street\namenity\nname\nwebsite\nwikidata\ngeometry\n\n\nelement_type\nosmid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nway\n1157021269\n[10759584855, 10759584856, 10759584857, 450404...\nBismarck\n3315\n58504\nND\nUniversity Drive\ncollege\nUnited Tribes Technical College\nhttps://uttc.edu/\nQ7893617\nPOLYGON ((-100.76305 46.76853, -100.76302 46.7...\n\n\n\n\n\n\n\n\nuttc_gdf.plot()\n\n/usr/share/miniconda/envs/learning-portal/lib/python3.10/site-packages/IPython/core/pylabtools.py:77: DeprecationWarning: backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nWe have a map of the UTTC Campus!\n\n\n\n\n\n\nWarning\n\n\n\nThe Open Street Maps (OSM) database is not always complete. For example, try searching for UTTC with the {'building': True}, and compare it to the map of the UTTC campus on their website. What do you notice?\n\n\n\n\n\nThere are lots of different ways to create maps and plots in Python. Here, we’re going to use a tool called 'hvplot' and 'geoviews' to create an interactive map, including the online 'EsriImagery' tile source basemap.\n\n# Plot UTTC boundary\nuttc_map = uttc_gdf.hvplot(\n    # Givethe map a descriptive title\n    title=\"United Tribes Technical College, Bismarck, ND\",\n    # Add a basemap\n    geo=True, tiles='EsriImagery',\n    # Change the colors\n    fill_color='white', fill_alpha=0.2,\n    line_color='skyblue', line_width=5,\n    # Change the image size\n    frame_width=400, frame_height=400)\n\n# Save the map as a file to put on the web\nhv.save(uttc_map, 'uttc.html')\n\n# Display the map\nuttc_map\n\nWARNING:bokeh.core.validation.check:W-1005 (FIXED_SIZING_MODE): 'fixed' sizing mode requires width and height to be set: figure(id='p1053', ...)\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\nIf you are doing this activity on GitHub Codespaces, you will need to download the map you created:\n\nOpen the Folders tab on the left hand side\nRight-click on uttc.html (or whatever you named your file)\nSelect Download...\n\nThis should download your map.\n\n\n\nYou are now ready to upload your map to your portfolio repository and place it in your webpage. Because it is HTML and not an image, you will need to use the following HTML to get it on your page:\n&lt;embed type=\"text/html\" src=\"uttc.html\" width=\"600\" height=\"600\"&gt;\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure to make the width and height of your embed element larger than the frame_width and frame_height of your plot, or it will get cut off!\n\n\n:::",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 5: Add a map"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/04-jekyll.html",
    "href": "pages/03-git-github/03-github-portfolio/04-jekyll.html",
    "title": "Spruce up your website",
    "section": "",
    "text": "Website themes are a system for applying a particular design to your web content. They consist of acollection of website configuration files, content templates, and style files that control how a website looks, but can be filled in with any content. Themes are great because: * Your website will immediately look and function like the theme * Most themes allow you to change style elements (like colors and fonts), and store data (like your name and email address) in a central location. * Themed websites will most likely work on lots of different devices, like phones, tablets, and computers. You can double-check if your theme mentions being adaptive or responsive, bu most themes these days are. * Some themes support interactive components like photo carousels or lightboxes without needing to write a lot of code\n\n\nJekyll is a system for building websites from Markdown, HTML, and CSS. In fact, Jekyll is the system that GitHub Pages uses to deploy websites. This means that we can take advantage of free Jekyll themes to make any website look great.\n\n\n\n\n\n\nCheck out our themes demo video!\n\n \n\nDEMO: Add a theme to your portfolio by ESIIL",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 4: Spruce up your site"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/04-jekyll.html#make-attractive-websites-with-themes",
    "href": "pages/03-git-github/03-github-portfolio/04-jekyll.html#make-attractive-websites-with-themes",
    "title": "Spruce up your website",
    "section": "",
    "text": "Website themes are a system for applying a particular design to your web content. They consist of acollection of website configuration files, content templates, and style files that control how a website looks, but can be filled in with any content. Themes are great because: * Your website will immediately look and function like the theme * Most themes allow you to change style elements (like colors and fonts), and store data (like your name and email address) in a central location. * Themed websites will most likely work on lots of different devices, like phones, tablets, and computers. You can double-check if your theme mentions being adaptive or responsive, bu most themes these days are. * Some themes support interactive components like photo carousels or lightboxes without needing to write a lot of code\n\n\nJekyll is a system for building websites from Markdown, HTML, and CSS. In fact, Jekyll is the system that GitHub Pages uses to deploy websites. This means that we can take advantage of free Jekyll themes to make any website look great.\n\n\n\n\n\n\nCheck out our themes demo video!\n\n \n\nDEMO: Add a theme to your portfolio by ESIIL",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 4: Spruce up your site"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/04-jekyll.html#jekyll-plays-well-with-github-pages",
    "href": "pages/03-git-github/03-github-portfolio/04-jekyll.html#jekyll-plays-well-with-github-pages",
    "title": "Spruce up your website",
    "section": "Jekyll plays well with GitHub Pages",
    "text": "Jekyll plays well with GitHub Pages\n\nSupported themes\nWe recommend starting out by using one of the GitHub Pages supported themes. Follow these instructions from GitHub.\nEven if you don’t ultimately end up using one of these themes, you can make sure that everything is working with one of these themes.\n\n\nRemote themes\nGitHub Pages allows you to add any Jekyll theme available on GitHub to your site with a configuration file.\nTo do this you can: 1. Choose the Jekyll theme you want to use (here are some examples). Note that some themes work more seamlessly than others, so you may have to try more than one. 2. Preview the theme by clicking Live Demo on jekyllthemes.io, or searching the GitHub README for a preview link. 3. Follow the instructions from GitHub on how to apply the theme using a _config.yml file. 4. Go to the GitHub repository for the theme by clicking on the Get THEME on GitHub button on jekyllthemes.io. Follow any instructions about customizing things like your name or the title of your webpage.\n\n\n\nSo what is YAML?\nThe _config.yml file is written in YAML, a human-readable format for structured information (lists and key/value pairs). Learn more about YAML on their website\nThe _config.yml file that you created to add a theme can also sometimes be used to change the title of your website from the default (the name of your repository). Check out the README for your theme to see what parameters are available For example, and example _config.yml file for the minimal theme looks like:\ntitle: J. Doe's Awesome Portfolio Website\ndescription: Check out my projects!\nlogo: img/headshot.png\nremote_theme: pages-themes/minimal@v0.2.0\n\n\n\n\n\n\nWarning\n\n\n\nYou may need or want to add a _data/data.yml file or your own templates in _layouts in addition to the _config.yml file, depending on your theme. You will need to read the README for the theme you are using to see what you can customize. We recommend copying any example configuration files from the theme repository, and then modifying them to meet your needs.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 4: Spruce up your site"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/02-images.html",
    "href": "pages/03-git-github/03-github-portfolio/02-images.html",
    "title": "Add images to your portfolio",
    "section": "",
    "text": "Follow along with our video demo here:\n\n \n\nDEMO: Add images to your portfolio by ESIIL",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 2: Add images"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/02-images.html#images-make-your-website-easier-to-understand",
    "href": "pages/03-git-github/03-github-portfolio/02-images.html#images-make-your-website-easier-to-understand",
    "title": "Add images to your portfolio",
    "section": "Images make your website easier to understand",
    "text": "Images make your website easier to understand\nThe following code will display an image from the internet using Markdown:\n![Mississippi Delta](https://deltax.jpl.nasa.gov/img/delta-google-earth.jpg)\n\n\n\nMississippi Delta\n\n\n\nImage source: image of the Mississippi Delta from the Jet Propulsion Laboratory DeltaX project\n\n\n\n\n\n\n\nImportant\n\n\n\nAlways make sure you have permission to use images, and give credit to your image sources. Most images are fair to use for education (teaching, research, and study), as long as you give credit to your source. If you later on decide to use your portfolio to make money (for example, if you use it as marketing materials), then you should reconsider what images you are using.\nLearn more about fair use from the CU Library Fair Use page.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 2: Add images"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/02-images.html#adding-your-own-images",
    "href": "pages/03-git-github/03-github-portfolio/02-images.html#adding-your-own-images",
    "title": "Add images to your portfolio",
    "section": "Adding your own images",
    "text": "Adding your own images\nIncluding images from the web is the easiest way to add images to your site, but you will probably want to include your own images! There are three common ways that you can add images you have taken or created to your website:\n\nUploading an image to your portfolio repository on GitHub\nUploading an image elsewhere and then linking to it\nGenerate an image with code and render it into your website\n\nWe’ll try out the first two options in this lesson. But first, you need to understand the difference between absolute and relative URLs on the web.\n\nAbsolute and relative links\nOn your website, you can link to files on the web, or you can link to local files.\nAbsolute URLs are on the web, and so they begin with something like http:// or https://. When you are using an absolute link, you don’t need to worry about your file structure – for example, what folder your Markdown file is in. If you move things around in your project the link will still work.\n\n\n\n\n\n\nWarning\n\n\n\nLinks on the internet aren’t forever. If you are using an absolute link, you should check on it occasionally to make sure it’s still there. You can also select image sources that are more reliable long term, or even an image with a permanent link or Digital Object Identifier (DOI).\n\n\nRelative links are to files that are local, or in the same location as your website. Keep in mind that what is local can change if you keep multiple copies of your repository, such as one on GitHub and one on your computer. Relative links, because they will change depending on the file and directory structure of your website. If you are working on your own computer, you can link to a file that isn’t in your repository, and then it won’t show up when you deploy your site.\n\n\n\n\n\n\n\nWhat is a directory?\n\n\n\nDirectory is another word for a folder on your computer – you can organize files by putting them in directories.\n\nThere’s a couple of special characters when using relative links. Suppose you have a Markdown file in a pages directory, and an image you want to display in an img folder:\n&lt;username&gt;.github.io/\n├── README.md\n├── pages/\n│   └── index.md\n└── img/\n    └── cool_satellite_image.jpeg\n\n\n\n\n\n\n\nSpeak Code: File Trees\n\n\n\nIn the text diagram to the left, indentation and lines are being used to show which files are inside which folders – for example the index.md file is indented under the pages directory and connected by a line, indicating that index.md is inside pages.\n\nWhen you are working in index.md, you are in the pages directory. If you want to go up a directory to &lt;username&gt;.github.io from pages, you can use ... For example, ../img/cool_satellite_image.jpeg.\nYou can also make website paths starting from the root directory of the site, in this case &lt;username&gt;.github.io, by starting the path with a slash character, /:\n\n\n\nKeyboard highlighting the slash key\n\n\nThe equivalent link to ../img/cool_satellite_image.jpeg would be /img/cool_satellite_image.jpeg.\n\n\nUpload an image to GitHub\n\nSTEP 1: Create an empty image directory on GitHub\nIt’s important to keep your files organized in a project like a website. Before uploading any images, you should make a place to put them. By convention, images in most websites are kept in the img directory, but you can name it whatever you want.\ngit, the system used by GitHub to keep track of changes to files, doesn’t keep a record of directories without any files in them, and as of now you can’t upload an image to a directory that doesn’t exist yet. This puts us in a bit of a pickle! Fortunately, there’s a common solution – we’ll create an empty text file named .keep in the new directory.\n\n\n\n\n\n\n\nSpeak Code – why .keep?\n\n\n\nYou could name your empty placeholder file anything you want. However, there are two good reasons to use .keep as your filename. First, files that start with a dot (.) are hidden in unix-based operating systems like linux and MacOS, which helps avoid clutter when you are looking at your files. Second, adhering to the convention means that anyone else looking at your repository will know what the .keep file is doing there.\n\nTo create a img/.keep file, go to the main page of your website repository on GitHub and click the Code tab. Then, find the + menu button on the upper right and select Add a file from the dropdown:\n\n\n\nClick add a file\n\n\nType `img/.keep into the name field and then commit your changes:\n\n\n\nName the file img/.keep and commit\n\n\n\n\n\nClick Commit\n\n\n\n\n\nClick Commit again to confirm\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen you type img/, GitHub will automatically make a folder, so only .keep will be visible in the text box.\n\n\n\n\nSTEP 2: Upload your image to the img directory\nFirst, make sure that the name of your image file on your computer is descriptive and machine-readable (doesn’t contain any spaces or special characters other than _, -, or .). You won’t be able to rename your file once you upload it to GitHub.\nYou should now be in the img directory in your repository. If note, you can get there from the Code tab in your website repository, by clicking on the img directory in the files. From there, click the Add file menu in the upper right, but this time select Upload files:\n\n\n\nClick on Add file, then Upload files\n\n\nDrag your image file, or browse and select it.\n\n\n\nCommit file upload\n\n\nFinally, write a message and click Commit changes: \n\n\n\nOther places to host images\nGitHub has a couple of limitations when it comes to hosting images:\n\nThe site will not allow you to upload files larger than 100MB\nIf you make changes to an image file, GitHub will keep all the previous versions, which can make your repository unwieldy to download. If you are generating image files yourself and changing them frequently, consider hosting them somewhere else.\n\nSo, where can you host images that you have taken or generated? There are a few options:\n\nYou can use the Free Image Hosting service to upload images without an account or giving up any information about yourself. Note that while you retain ownership of these images you are granting a license to Free Image Hosting to use them however they want.\nFor a final version, you can use a research hosting service like figshare to upload images and get code to embed them in your website.\nIf you want to use photos you have already uploaded to social media, you can usually get a direct link by right-clicking on the image and selecting Copy Image Link.\nYou will likely find that most file storage services such as Google Drive and Dropbox don’t provide you with a direct link to images that you can use in a website. You can look for instructions on generating direct links for these files, but they are often unsupported and could change without warning.\nThere’s another way of hosting on GitHub that doesn’t have the same drawbacks when it comes to large files. You can include files in a release, which creates a direct link to files, but does not attempt to track changes. To get started, follow the instructions from GitHub documentation. Note that once you have a release you can add additional files to it.\n\n\n\n\n\n\n\nWarning\n\n\n\nBy uploading images to social media or other hosting services, you are sometimes giving up your rights to the image, or granting. Photo apps like Flickr are usually better bets, since they are built for photographers with copyright protection in mind. But be sure to read the fine print when uploading material that is sensitive to you personal or to your community – you can look for the term ownership rights in the Terms and Conditions of whatever sites you use.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 2: Add images"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html",
    "href": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html",
    "title": "Create your own portfolio webpage",
    "section": "",
    "text": "GitHub is a powerful software development tool owned and operated by Microsoft. It is used almost universally for software development and scientific projects. It lets you: * Keep track of all the changes you have ever made, when, and why * Collaborate with others * Get your code online so you can access it anywhere * Use a cloud platform to run your code * Publish a website in minutes We’ll be focusing on that last feature in this activity, in which you will create and publish your own online portfolio website. Read more about git and GitHub in our open Earth Data Science textbook pages.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 1: Publish a website"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-0-create-a-github-account",
    "href": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-0-create-a-github-account",
    "title": "Create your own portfolio webpage",
    "section": "Step 0: Create a GitHub account",
    "text": "Step 0: Create a GitHub account\nUse this link to create a free GitHub account.\n\n\n\n\n\n\nWarning\n\n\n\nIf you already have a GitHub account, there is no need to create a new account!",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 1: Publish a website"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-1-create-a-repository",
    "href": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-1-create-a-repository",
    "title": "Create your own portfolio webpage",
    "section": "Step 1: Create a repository",
    "text": "Step 1: Create a repository\nOnce you have a GitHub account, get started by creating a new repository for your webpage. There are several ways to accomplish this task.\n\n\n\n\n\n\nWarning\n\n\n\nSometimes buttons on GitHub are blue instead of green.\n\n\n\n\n\n\n\n\n\nWhat is a repository?\n\n\n\nA GitHub repository is a collection of code, documentation, and configuration files. All changes you make in a repository will be tracked using the version control system git. You can discuss and manage your project’s work within the repository.\n\nTo do this you can:\n\nNavigate to your profile page\nClick on the dropdown arrow next to your profile photo in the upper right corner\nSelect Your profile\n\n\n\nSelect Your profile\n\n\nSelect the Repositories tab from the menu near the top of the page.\n\n\n\nSelect the Repositories tab from the menu near the top of the page.\n\n\nFrom here, you can select the green New button on the right to get started.\n\n\n\nSelect the green New button on the right to get started\n\n\nCustomize the settings:\n\nGive your repository a short and descriptive name. We recommend &lt;yourusername&gt;.github.io because it results in the simplest url for your website.\nGive your repository a description\nMake your repository Public\nYou can skip adding the gitignore file for now\nAdd a README so your repository home page (on GitHub, NOT your published website) will include your title and description\nChoose a License for your repository. Check out choosealicense.com for more information about popular options.\n\nOnce you’re done, select the green Create Repository button at the bottom of the page\n\n\n\n\n\n\n\n\nSpeak Code\n\n\n\nWhen reading code snippets, the &lt; and &gt; symbols are usually used to surround text you should replace. Do not leave the &lt; and &gt; symbols in place!. For example, in this case your repository name would be jdoe.github.io, if jdoe was your GitHub username. There’s a BIG exception to this rule when it comes to building websites – &lt; and &gt; are key characters if you are using HTML. Read more about HTML.\n\n\n\n\n\n\n\nLicenses\n\n\n\nA license, copyright, and data rights or data sovereignty are all slightly different. A license is about whether and how someone else can use the code in your repository. Copyright is about the text published on your website, and data rights are about whether and how others can use your data",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 1: Publish a website"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-2-create-a-new-index.md-file",
    "href": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-2-create-a-new-index.md-file",
    "title": "Create your own portfolio webpage",
    "section": "Step 2: Create a new index.md file",
    "text": "Step 2: Create a new index.md file\nYou will create a new file called index.md that will serve as the content for your webpage. To do this you can :\n\nSelect the Add file button from the menu on the right\nSelect Create new file.\n\n\n\nSelect Create new file.\n\n\nName your new Markdown file index.md. This will make it the home page of your website. Then, add a Markdown header text to your index file, e.g.\n\n# A fabulous Earth Data Science Portfolio\n\n\n\n\n\n\nNote\n\n\n\nYou can change this text to your name or something else. This is your website, and you’ll always be able to come back and make edits!",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 1: Publish a website"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-3-commit-changes",
    "href": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-3-commit-changes",
    "title": "Create your own portfolio webpage",
    "section": "Step 3: Commit changes",
    "text": "Step 3: Commit changes\nNow that you’ve created your index.md file and added some text, you’ll want to commit changes to your repository. Add an optional extended description of your changes and then select the green Commit changes button at the bottom of the page.\n\n\n\nCommit changes",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 1: Publish a website"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-4-build-your-webpage",
    "href": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-4-build-your-webpage",
    "title": "Create your own portfolio webpage",
    "section": "Step 4: Build your webpage",
    "text": "Step 4: Build your webpage\nOnce you’ve created your index.md file you’re ready to build your webpage:\n\nFrom your repository, select the Settings tab from the right end of the menu.\n\n\n\nNavigate to your repository settings\n\n\nFrom here, scroll down the menu on the left and select Pages.\n\n\n\nSelect the Pages settings tab\n\n\nNow you’ll want to select the main option under the Branch heading and then select Save.\n\n\n\nSelect the main branch in your repository",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 1: Publish a website"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-5-check-on-your-webpage",
    "href": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-5-check-on-your-webpage",
    "title": "Create your own portfolio webpage",
    "section": "Step 5: Check on your webpage",
    "text": "Step 5: Check on your webpage\nCheck in on your webpage to see how it is doing by opening the link https://username.github.io/ in a new tab in your web browser. Here, you’ll need to replace username with your GitHub username. Once you see your name (or whatever text you added to your index.md file in Step 2) appear as a Markdown header, then you know your webpage is working!\n\n\n\n\n\n\nNote\n\n\n\nSometimes your webpage can take a minute or so to build so be patient and refresh every 30 seconds or so until the page is done building. You can track the progress in the Actions tab.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 1: Publish a website"
    ]
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-6-start-adding-information-to-your-webpage",
    "href": "pages/03-git-github/03-github-portfolio/01-create-portfolio-website.html#step-6-start-adding-information-to-your-webpage",
    "title": "Create your own portfolio webpage",
    "section": "Step 6: Start adding information to your webpage",
    "text": "Step 6: Start adding information to your webpage\n\n\n\n\n\n\n\nNote\n\n\n\nReview the **Markdown Basic Syntax guide to help you format your webpage using Markdown and HTML. We also have a lesson in our Earth Data Science textbook that may be helpful.\n\nNow you’re ready to start adding some more information to your webpage. Navigate back to your repository and open the index.md file that you just created. You will edit this page by clicking on the pencil icon on the right of the menu near the top of your repository page on GitHub. You will use Markdown and Hypertext Markup Language (HTML) to add text, links, images, and other content to your webpage. Markdown and HTML are both common markup langauges, and have wide application including formatting text, report writing, and website development.\n\n\n\nEdit a file on GitHub\n\n\n\nHere you should think about adding the following information to your webpage:\n\nYour name (as a header) if you haven’t already\nA bulleted list of links to your public contact information (email, GitHub account, LinkedIn account, social media accounts, etc.)\nYour educational and professional background\nA biographical paragraph about yourself\nWhat you’re excited about learning about Earth Data Science\nQuestions that you’d like to answer using Earth Data Science\n\nYou should also plan to add a photo of yourself and/or where you live. We’ll go over how to add and customize images on your page in the next two lessons.\n\n\n\n\n\n\nWarning\n\n\n\nAlways remember to commit changes so that your updated content gets added to your webpage.",
    "crumbs": [
      "ESIIL Stars Home",
      "UNIT 1: Build Your Online Portfolio",
      "STEP 1: Publish a website"
    ]
  }
]